{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/rahultheogre/marketing-eda-preprocessing-visualization?scriptVersionId=87308124\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-28T01:03:35.535854Z","iopub.execute_input":"2022-01-28T01:03:35.536395Z","iopub.status.idle":"2022-01-28T01:03:35.554937Z","shell.execute_reply.started":"2022-01-28T01:03:35.536294Z","shell.execute_reply":"2022-01-28T01:03:35.554101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Domain: Marketing, Retail\n##### Background:\n- Marketing analytics is the study of data gathered through marketing campaigns in order to analyse patterns between such things as how a campaign contributed to conversions, consumer behavior,regional preferences, creative preferences and much more. The goal of marketing analytics as a practice is to use these patterns and findings to optimize future campaigns based on what was successful.\n- Marketing analytics benefits both marketers and consumers. This analysis allows marketers to achieve higher return of investment on marketing investments by understanding what is successful in driving conversions, brand awareness and improvement related to sales, inventory, targeting customers, and other important crucial aspects.\n\n#### Data Description:\n1. ID: Customer's unique identifier\n2. Year_Birth: Customer's birth year\n3. Education: Customer's education level\n4. Marital_Status: Customer's marital status\n5. Income: Customer's yearly household income\n6. Kidhome: Number of children in customer's household\n7. Teenhome: Number of teenagers in customer's household\n8. Dt_customer: Date of customer's enrollment with the company\n9. Recency: Number of days since customer's last purchase\n10. MntWines: Amount spent on wine in the last 2 years\n11. MntFruits: Amount spent on fruits in the last 2 years\n12. MntMeatProducts: Amount spent on meat in the last 2 years\n13. MntFishProducts: Amount spent on fish in the last 2 years\n14. MntSweetProducts: Amount spent on sweets in the last 2 years\n15. MntGoldProds: Amount spent on gold in the last 2 years\n16. NumDealsPurchases: Number of purchases made with a discount\n17. NumWebPurchases: Number of purchases made through the company's web site\n18. NumCatalogPurchases: Number of purchases made using a catalogue\n19. NumStorePurchases: Number of purchases made directly in stores\n20. NumWebVisitsMonth: Number of visits to company's web site in the last month\n21. AcceptedCmp3: 1 if customer accepted the offer in the 3rd campaign, 0 otherwise\n22. AcceptedCmp4: 1 if customer accepted the offer in the 4th campaign, 0 otherwise\n23. AcceptedCmp5: 1 if customer accepted the offer in the 5th campaign, 0 otherwise\n24. AcceptedCmp1 1 if customer accepted the offer in the 1st campaign, 0 otherwise\n25. AcceptedCmp2: 1 if customer accepted the offer in the 2nd campaign, 0 otherwise\n26. Response: 1 if customer accepted the offer in the last campaign, 0 otherwise\n27. Complain: 1 if customer complained in the last 2 years, 0 otherwise\n28. Country: Customer's location\n\n\n### Problem Statement:\n- You're a marketing analyst and you've been told by the Senior Marketing Manager that recent marketing campaigns have not been as effective as they were expected to be. You need to analyze the data set in order to understand this problem and propose data-driven solutions. You are required to solve the following questions to generate a report for your management.","metadata":{}},{"cell_type":"markdown","source":"### 1. Import necessary libraries and load the dataset and display random 5 samples. Check the info of the data and write your findings. (1 point)","metadata":{}},{"cell_type":"code","source":"import numpy as np # for linear algebra\nimport pandas as pd # for data processing\n\nimport matplotlib.pyplot as plt #for data visualization\nimport seaborn as sns #data visualization #wrapper to matplotlib\n\n#to make figures visible in jupyter notebook cells \n#no need to use plt.show() again and again\n%matplotlib inline \n\n#filtering the warnings while plotting\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-01-28T01:03:35.556419Z","iopub.execute_input":"2022-01-28T01:03:35.557223Z","iopub.status.idle":"2022-01-28T01:03:36.014891Z","shell.execute_reply.started":"2022-01-28T01:03:35.557173Z","shell.execute_reply":"2022-01-28T01:03:36.013421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mdata = pd.read_csv('../input/markettingdata/marketing_data.csv')\nmdata.sample(5)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T01:03:36.016288Z","iopub.execute_input":"2022-01-28T01:03:36.016627Z","iopub.status.idle":"2022-01-28T01:03:36.055813Z","shell.execute_reply.started":"2022-01-28T01:03:36.016593Z","shell.execute_reply":"2022-01-28T01:03:36.054942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- It would be better to have the data sorted to keep things under control.\n- Let us sort it according to ID which is an obvious choice","metadata":{}},{"cell_type":"code","source":"mdata.sort_values('ID',axis=0,ascending=True,inplace=True)\nmdata.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-28T01:03:36.058392Z","iopub.execute_input":"2022-01-28T01:03:36.059261Z","iopub.status.idle":"2022-01-28T01:03:36.081695Z","shell.execute_reply.started":"2022-01-28T01:03:36.059214Z","shell.execute_reply":"2022-01-28T01:03:36.080857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mdata.info()","metadata":{"execution":{"iopub.status.busy":"2022-01-28T01:03:36.083149Z","iopub.execute_input":"2022-01-28T01:03:36.084026Z","iopub.status.idle":"2022-01-28T01:03:36.102084Z","shell.execute_reply.started":"2022-01-28T01:03:36.083983Z","shell.execute_reply":"2022-01-28T01:03:36.101269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Findings:\n1. Income attribute with NaN values. It's values also need to be properly formatted.\n2. All names written in proper format (legible to computer for analysis) except for ' Income' which has a few spaces in front and can be problematic during EDA\n3. 5 object types and 23 int types.\n4. Many categorical variables, a quite a few of them already hot-encoded\n5. Attribute values like Income and Dt_Customers need to be formatted properly\n6. Decent number of records to work with.\n","metadata":{}},{"cell_type":"markdown","source":"### 2. Check the following using an appropriate method and write your findings (1 point)\n1. Check how spread out or varied your data set is.\n2. Check where the middle 50% of your data lies.\n3. Check boundaries for the lower, middle and upper quarters of data.","metadata":{}},{"cell_type":"code","source":"mdata.describe().T","metadata":{"execution":{"iopub.status.busy":"2022-01-28T01:03:36.103717Z","iopub.execute_input":"2022-01-28T01:03:36.104021Z","iopub.status.idle":"2022-01-28T01:03:36.17722Z","shell.execute_reply.started":"2022-01-28T01:03:36.103979Z","shell.execute_reply":"2022-01-28T01:03:36.176357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- describe() method gives us summary statistics of a dataframe focussing on numerical data unless include='all' is fed in\n- many variables in the dataset 'mdata' are hot-encoded as 0/1 which the compiler reads are numerical. their summary stats are useless. So we will focus only on\n- 'Income','Kidhome','Teenhome','Recency','MntWines','MntFruits','MntMeatProducts','MntFishProducts','MntSweetProducts','MntGoldProds','NumDealsPurchases','NumWebPurchases','NumCatalogPurchases','NumStorePurchases','NumWebVisitsMonth'\n- they are proper numerical variables whose summary stats make sense.","metadata":{}},{"cell_type":"markdown","source":"##### interesting findings\n- One customer was born on 1893, which can be interesting. But of course, we do not know **when** the data was collected. We will take the findings to be current for an analysis. So one customer is around 130 years old. (Written in 2022). On avergae (using median), a customer was born on 1970.\n- ","metadata":{}},{"cell_type":"markdown","source":"### 3. Check for any missing values in the dataset and handle them using an appropriate method. (1 point)","metadata":{}},{"cell_type":"markdown","source":"- isna() methods gives a DataFrame of all the attributes in on column, and bool values in the second column\n- True (1) stands for Yes, and False(0) stands for no.\n- sum() methods sums those bool values gives us a Series of Attributes as keys and sum of NaNs as corresponding values.","metadata":{}},{"cell_type":"code","source":"mdata.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-01-28T01:03:36.178454Z","iopub.execute_input":"2022-01-28T01:03:36.178807Z","iopub.status.idle":"2022-01-28T01:03:36.1875Z","shell.execute_reply.started":"2022-01-28T01:03:36.178772Z","shell.execute_reply":"2022-01-28T01:03:36.186957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Income attribute has 24 NaNs.\n- Before working on them, first I have to deal with two issues:\n    1. Removing the unnecesary space before the word 'Income'\n    2. Removing the presence of special characters in it, and typecast as float.\n- Only then can I impute them properly.\n- Thus, I am solving part of the PROBLEM 4. (Note to examiner)","metadata":{}},{"cell_type":"code","source":"#getting the column value of Income\nmdata.columns[4]","metadata":{"execution":{"iopub.status.busy":"2022-01-28T01:03:36.188673Z","iopub.execute_input":"2022-01-28T01:03:36.189371Z","iopub.status.idle":"2022-01-28T01:03:36.20202Z","shell.execute_reply.started":"2022-01-28T01:03:36.189326Z","shell.execute_reply":"2022-01-28T01:03:36.201075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Clearly, Income has spaces before and after both\n#Removing the unnesary spaces before and after the word 'Income' by renaming it\n\nmdata.rename(columns={' Income ':'Income'},inplace=True)\nmdata.columns[4]","metadata":{"execution":{"iopub.status.busy":"2022-01-28T01:03:36.203806Z","iopub.execute_input":"2022-01-28T01:03:36.204118Z","iopub.status.idle":"2022-01-28T01:03:36.214255Z","shell.execute_reply.started":"2022-01-28T01:03:36.204077Z","shell.execute_reply":"2022-01-28T01:03:36.213666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- So we have successfully removed the spaces before and after the word Income.\n- Now, removing the presence of special characters in Income column rows. And typecasting it as int64.","metadata":{}},{"cell_type":"code","source":"mdata['Income'].sample(5)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T01:03:36.215536Z","iopub.execute_input":"2022-01-28T01:03:36.216061Z","iopub.status.idle":"2022-01-28T01:03:36.225858Z","shell.execute_reply.started":"2022-01-28T01:03:36.21602Z","shell.execute_reply":"2022-01-28T01:03:36.224864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1. We see 'Income' has a dollar sign and a comma in between which are unnecessary. We will remove them by replacing each of them with '' using replace() method of str object.\n2. I will also change it to float even though it contains NaNs. Because Pandas reads NaNs as floats.","metadata":{}},{"cell_type":"code","source":"mdata['Income'] = mdata['Income'].str.replace('$','')\nmdata['Income'] = mdata['Income'].str.replace(',','').astype(float)\nmdata['Income'].sample(5) #checking results","metadata":{"execution":{"iopub.status.busy":"2022-01-28T01:03:36.226985Z","iopub.execute_input":"2022-01-28T01:03:36.227311Z","iopub.status.idle":"2022-01-28T01:03:36.241889Z","shell.execute_reply.started":"2022-01-28T01:03:36.227282Z","shell.execute_reply":"2022-01-28T01:03:36.241055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Now let us analyse the Income column to choose a valid method for imputing 24 missing values.\n- Income is an important variable. Even though we have 2240 records, we can't just remove the records corresponding to missing income values. \n- Income of a customer plays a major role in setting his purchasing habits.\n- Let's see the summary statistics of 'Income'.","metadata":{}},{"cell_type":"code","source":"mdata['Income'].describe().T","metadata":{"execution":{"iopub.status.busy":"2022-01-28T01:03:36.243101Z","iopub.execute_input":"2022-01-28T01:03:36.24335Z","iopub.status.idle":"2022-01-28T01:03:36.252781Z","shell.execute_reply.started":"2022-01-28T01:03:36.243322Z","shell.execute_reply":"2022-01-28T01:03:36.251889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"median = mdata['Income'].median()\nprint(f\"Also, Median is {median}\")","metadata":{"execution":{"iopub.status.busy":"2022-01-28T01:03:36.257734Z","iopub.execute_input":"2022-01-28T01:03:36.25818Z","iopub.status.idle":"2022-01-28T01:03:36.263345Z","shell.execute_reply.started":"2022-01-28T01:03:36.258133Z","shell.execute_reply":"2022-01-28T01:03:36.262801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 75th percentile value is 68522. Median is 51381.5. Mean is 52247.\n- But Max is 666666. So the data seems to be right-skewed. But it is not as clearly, 666666 is an outlier, for Mean and Median are almost same.\n- Let's confirm with a histogram","metadata":{}},{"cell_type":"code","source":"ax = sns.histplot(mdata['Income'],kde=True,bins=20)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T01:03:36.26446Z","iopub.execute_input":"2022-01-28T01:03:36.264738Z","iopub.status.idle":"2022-01-28T01:03:36.557622Z","shell.execute_reply.started":"2022-01-28T01:03:36.264708Z","shell.execute_reply":"2022-01-28T01:03:36.556693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- My assertion was right. There is mild skewness. But it does not rule over the data.\n- So we will impute missing values with Median, which conveniently lies betweeb 0 and 100000 - our normal distribution part of the curve. \n- We use fillna() method for imputation.","metadata":{}},{"cell_type":"code","source":"mdata['Income']=mdata['Income'].fillna(mdata['Income'].median())\n\n#we can check if the NaN values have been removed by :\nmdata['Income'].isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-01-28T01:03:36.559105Z","iopub.execute_input":"2022-01-28T01:03:36.559424Z","iopub.status.idle":"2022-01-28T01:03:36.566931Z","shell.execute_reply.started":"2022-01-28T01:03:36.559383Z","shell.execute_reply":"2022-01-28T01:03:36.566341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So, missing values in the dataset have been handled.","metadata":{}},{"cell_type":"markdown","source":"### 4. Check for any presence of special characters in any variables. If present, clean/replace and change the datatype of the variable if required. (1 point)","metadata":{}},{"cell_type":"markdown","source":"- part of this question was done earlier when I handled Income attribute. Unnecessary signs were removed and it was changed to float.\n- let's check each attribute.\n- There are around 28 attributes in this dataset, but, as we saw earlier, Jupyter does not display all of them. \n- By default in usual machines, it displays only 20 columns. So I use set_option method of pandas to set the limit to None\n- And check one by one for inconsstencies in data.","metadata":{}},{"cell_type":"code","source":"pd.set_option(\"display.max_columns\", None)\nmdata.head(7)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T01:03:36.567892Z","iopub.execute_input":"2022-01-28T01:03:36.5681Z","iopub.status.idle":"2022-01-28T01:03:36.595297Z","shell.execute_reply.started":"2022-01-28T01:03:36.568075Z","shell.execute_reply":"2022-01-28T01:03:36.594727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mdata.info()","metadata":{"execution":{"iopub.status.busy":"2022-01-28T01:03:36.596405Z","iopub.execute_input":"2022-01-28T01:03:36.596659Z","iopub.status.idle":"2022-01-28T01:03:36.613962Z","shell.execute_reply.started":"2022-01-28T01:03:36.596629Z","shell.execute_reply":"2022-01-28T01:03:36.613127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Year_Birth is int. We don't really need to change Year_Birth into datetime format. WE CAN CHANGE IT NOW AND CHANGE BACK. But our task is not to present data in valid formats, but reach conclusion. And manipulation with Int is always better than datetime. Anyway, if we really need it, we will do it.\n- Dt_Cutstomer is an int. We will change it to DateTime.\n- Rest of the Attribute values seem okay.","metadata":{}},{"cell_type":"code","source":"#converting Dt_Customer into a Datetime object with to_datetime function\nmdata['Dt_Customer']=pd.to_datetime(mdata['Dt_Customer'], format='%m/%d/%y')","metadata":{"execution":{"iopub.status.busy":"2022-01-28T01:03:36.615422Z","iopub.execute_input":"2022-01-28T01:03:36.616359Z","iopub.status.idle":"2022-01-28T01:03:36.63234Z","shell.execute_reply.started":"2022-01-28T01:03:36.616312Z","shell.execute_reply":"2022-01-28T01:03:36.631716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking\nmdata.info()","metadata":{"execution":{"iopub.status.busy":"2022-01-28T01:03:36.634419Z","iopub.execute_input":"2022-01-28T01:03:36.63469Z","iopub.status.idle":"2022-01-28T01:03:36.654129Z","shell.execute_reply.started":"2022-01-28T01:03:36.634661Z","shell.execute_reply":"2022-01-28T01:03:36.653264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As one can see, the object types have been successfully changed.","metadata":{}},{"cell_type":"markdown","source":"### 5. The Marketing Manager wants to know the 'Age' of the customers. Extract the feature age from the given dataset and display the statistical summary of the age? (2 points)","metadata":{}},{"cell_type":"markdown","source":"- We know the Customers' Year of Birth in Year_birth attribute. It is int.\n- We will use it to produce a new feature 'Age' from 'Year_Birth' column \n- I will use **list comprehension** to iterate through elements of 'Year_Birth' column ","metadata":{}},{"cell_type":"code","source":"import datetime\nfrom datetime import date #we use datetime library to get the current date (now)\ncurrent_year = date.today().year #current year is assigned to variable 'current_year'\n\nmdata['Age'] = [(current_year-x) for x in mdata['Year_Birth']]\nprint(\"Statistical summary of feature 'Age' is:\")\nmdata['Age'].describe()","metadata":{"execution":{"iopub.status.busy":"2022-01-28T01:03:36.655282Z","iopub.execute_input":"2022-01-28T01:03:36.655511Z","iopub.status.idle":"2022-01-28T01:03:36.668507Z","shell.execute_reply.started":"2022-01-28T01:03:36.655483Z","shell.execute_reply":"2022-01-28T01:03:36.667987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### NOW, we will change the type of data in 'Dt_Customer' Column\n- It would have been a case of overcoding dealing with Year_Birth in DateTime form\n- Always better to resuse codes.\n\n### Part of Q. 4","metadata":{}},{"cell_type":"code","source":"#changing Year_Birth\nmdata['Year_Birth']=pd.to_datetime(mdata['Year_Birth'],format='%Y')\nprint(f\"Now the data type of values in Year_Birth is {mdata['Year_Birth'].dtypes}\")","metadata":{"execution":{"iopub.status.busy":"2022-01-28T01:03:36.669526Z","iopub.execute_input":"2022-01-28T01:03:36.670173Z","iopub.status.idle":"2022-01-28T01:03:36.685141Z","shell.execute_reply.started":"2022-01-28T01:03:36.67014Z","shell.execute_reply":"2022-01-28T01:03:36.684568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 6. The Marketing manager wants to understand the total amount spent on various products so that we can find what percentage of the amount is spent on which product. (2 points)\n    a. Find out the total amount spent by a customer.\n    b. Display the Percentage of the amount spent on Wines and other products.","metadata":{}},{"cell_type":"markdown","source":"> Total amount spent on various products can be seen in the following attrbutes:\n* MntWines: Amount spent on wine in the last 2 years\n* MntFruits: Amount spent on fruits in the last 2 years\n* MntMeatProducts: Amount spent on meat in the last 2 years\n* MntFishProducts: Amount spent on fish in the last 2 years\n* MntSweetProducts: Amount spent on sweets in the last 2 years\n* MntGoldProds: Amount spent on gold in the last 2 years","metadata":{}},{"cell_type":"markdown","source":"- We create a new column named 'Total_amount' by concatenating the above six attributes.","metadata":{}},{"cell_type":"code","source":"mdata['Total_amount'] = mdata['MntWines']+ mdata['MntFruits']+mdata['MntMeatProducts']+mdata['MntFishProducts']+mdata['MntSweetProducts']+mdata['MntGoldProds']\n\n#total spent by each customer can be represented in the form of a new tempDf with attributes 'ID' and 'Total_Amount'\nprint(\"Total amount spent by each customer is tabulated as follows:\\n\")\ntempDF={'CustomerID':mdata['ID'],'Total Amount':mdata['Total_amount']}\npd.concat(tempDF,axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T01:03:36.686353Z","iopub.execute_input":"2022-01-28T01:03:36.686699Z","iopub.status.idle":"2022-01-28T01:03:36.703564Z","shell.execute_reply.started":"2022-01-28T01:03:36.686666Z","shell.execute_reply":"2022-01-28T01:03:36.702962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Now onto the second part. We have six products to focus on.\n- I would make a new DataFrame and display the percentage of each othe","metadata":{}},{"cell_type":"code","source":"#We first declare six Series\nk=100/mdata['Total_amount']\nWinesP = mdata['MntWines']*k\nFruitsP = mdata['MntFruits']*k\nMeatP = mdata['MntMeatProducts']*k\nFishP = mdata['MntFishProducts']*k\nSweetsP = mdata['MntSweetProducts']*k\nGoldP = mdata['MntGoldProds']*k\n\nID = mdata['ID'] #also ID for proper reporting\n\nprint(\"Percentage of the amount spent on various products is as follows:\")\ntempDF = {'CustomerID':mdata['ID'],'Wines':WinesP,'Fruits':FruitsP,'Meat':MeatP,'Sweets':SweetsP,'Gold':GoldP,'Fish':FishP}\npd.concat(tempDF,axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T01:03:36.704818Z","iopub.execute_input":"2022-01-28T01:03:36.705492Z","iopub.status.idle":"2022-01-28T01:03:36.730478Z","shell.execute_reply.started":"2022-01-28T01:03:36.705457Z","shell.execute_reply":"2022-01-28T01:03:36.729701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 7. Being an Analyst understands the total number of purchases made through different channels which can help find the percentage these channels contribute. (2 points)\n- a. Find out the total purchases done by a customer through different channels.\n- b. Display the percentage of the store and other channels’ contribution to the total purchases.","metadata":{}},{"cell_type":"markdown","source":"- We have the following data:\n    - NumWebPurchases: Number of purchases made through the company's web site\n    - NumCatalogPurchases: Number of purchases made using a catalogue\n    - NumStorePurchases: Number of purchases made directly in stores\n- We use the same steps as in previous question to make a new column total_purchase","metadata":{}},{"cell_type":"code","source":"mdata['total_purchase'] = mdata['NumWebPurchases'] + mdata['NumCatalogPurchases'] + mdata['NumStorePurchases']\nprint(\"The total numbers of purchases done by each customer is as follows:\")\ntempDF = {'Customer Id': mdata['ID'],'Net Purchase':mdata['total_purchase']}\npd.DataFrame(tempDF)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T01:03:36.731671Z","iopub.execute_input":"2022-01-28T01:03:36.731965Z","iopub.status.idle":"2022-01-28T01:03:36.746111Z","shell.execute_reply.started":"2022-01-28T01:03:36.731934Z","shell.execute_reply":"2022-01-28T01:03:36.745347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"k=100/mdata['total_purchase']\nWebP = mdata['NumWebPurchases']*k\nCatalogP = mdata['NumCatalogPurchases']*k\nStoreP = mdata['NumStorePurchases']*k\n\nprint('Percent of purchase category wise is as follows:')\ntempDF={'CustomerID':mdata['ID'],'Web': WebP,'Catalog':CatalogP,'Store':StoreP}\npd.DataFrame(tempDF)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T01:03:36.747347Z","iopub.execute_input":"2022-01-28T01:03:36.7478Z","iopub.status.idle":"2022-01-28T01:03:36.770539Z","shell.execute_reply.started":"2022-01-28T01:03:36.747766Z","shell.execute_reply":"2022-01-28T01:03:36.769753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 8. The marketing manager wants to understand the performance of different marketing campaigns. Find out which marketing campaign is most successful? Use suitable graphs for visualization. (Hint:- use features like AcceptedCmp for campaign information) (1 point )","metadata":{}},{"cell_type":"markdown","source":"- Attributes of concern:\n    - AcceptedCmp3: 1 if customer accepted the offer in the 3rd campaign, 0 otherwise\n    - AcceptedCmp4: 1 if customer accepted the offer in the 4th campaign, 0 otherwise\n    - AcceptedCmp5: 1 if customer accepted the offer in the 5th campaign, 0 otherwise\n    - AcceptedCmp1: 1 if customer accepted the offer in the 1st campaign, 0 otherwise\n    - AcceptedCmp2: 1 if customer accepted the offer in the 2nd campaign, 0 otherwise\n    - Response: 1 if customer accepted the offer in the last campaign, 0 otherwise","metadata":{}},{"cell_type":"markdown","source":"- There were six marketting campaigns in total. Some customers responded to the first, some to the second... and some to the last, which is represented in the Response attribute.\n- These are categorical variables with 1 and 0 indicative of Success and Failure.\n- We find success rate of each campaign by calculating the total number of customers getting attracted by each campaign- which is sum of each of the columns.\n- Then we represent it all in a piechart.","metadata":{}},{"cell_type":"code","source":"First = mdata['AcceptedCmp1'].sum()\nSecond = mdata['AcceptedCmp2'].sum()\nThird = mdata['AcceptedCmp3'].sum()\nFourth = mdata['AcceptedCmp4'].sum()\nFifth = mdata['AcceptedCmp5'].sum()\nLast = mdata['Response'].sum()\n\n#let us draw a piechart to visualize the results\n\ndata = [First,Second,Third,Fourth,Fifth,Last]\nlabels=['First','Second','Third','Fourth','Fifth','Last']\nax = plt.pie(data,labels=labels,radius=2,autopct='%.2f')\n#let us draw a piechart to visualize the results\n\ndata = [First,Second,Third,Fourth,Fifth,Last]\nlabels=['First','Second','Third','Fourth','Fifth','Last']\nax = plt.pie(data,labels=labels,radius=2,autopct='%.2f')","metadata":{"execution":{"iopub.status.busy":"2022-01-28T01:03:36.771695Z","iopub.execute_input":"2022-01-28T01:03:36.771913Z","iopub.status.idle":"2022-01-28T01:03:36.959608Z","shell.execute_reply.started":"2022-01-28T01:03:36.771887Z","shell.execute_reply":"2022-01-28T01:03:36.958595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Clearly the last campaign is the most successful hoarding as much as **33.37 percent** of whole conversion. We expected the last campaign to be more successful as it also reaps the benefts of previous campaigns\")","metadata":{"execution":{"iopub.status.busy":"2022-01-28T00:15:23.74974Z","iopub.execute_input":"2022-01-28T00:15:23.750052Z","iopub.status.idle":"2022-01-28T00:15:23.754203Z","shell.execute_reply.started":"2022-01-28T00:15:23.750015Z","shell.execute_reply":"2022-01-28T00:15:23.753642Z"}}},{"cell_type":"markdown","source":"### 9. The marketing manager wants to understand which products are performing the best and which are performing the least in terms of revenue. Being an analyst, analyse the data and plot a suitable graph to display a report on revenue generated by different products. (2 points)","metadata":{}},{"cell_type":"code","source":"WinesR = mdata['MntWines'].sum()\nFruitsR = mdata['MntFruits'].sum()\nMeatR = mdata['MntMeatProducts'].sum()\nFishR = mdata['MntFishProducts'].sum()\nSweetsR = mdata['MntSweetProducts'].sum()\nGoldR = mdata['MntGoldProds'].sum()\n\ndata=[WinesR,FruitsR,MeatR,FishR,SweetsR,GoldR]\nlabels= ['Wines','Fruits','Meat','Fish','Sweets','Gold']\nprint(\"Revenue generated by different products can be visualized in the following chart:\")\nax = plt.pie(data,autopct='%.2f',radius=2,labels=labels)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T01:03:36.961152Z","iopub.execute_input":"2022-01-28T01:03:36.961489Z","iopub.status.idle":"2022-01-28T01:03:37.108002Z","shell.execute_reply.started":"2022-01-28T01:03:36.961442Z","shell.execute_reply":"2022-01-28T01:03:37.107143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Clearly **Wines** are performing the best in generating revenue with a 50% share\n- And **Fruits** are performing the least with 4.34 percent of share.","metadata":{}},{"cell_type":"markdown","source":"### 10. The team wants to understand if there’s any pattern between the age of customers and the last campaign acceptance rate. Plot a suitable graph to visualize the distribution of the age with respect to customers who accepted the last campaign. (1 point)","metadata":{}},{"cell_type":"markdown","source":"- We plot a boxplot in seaborn between 'Age' and 'Response'. \n- Response is a categorical variable with only two possible options.\n- The graph will show the spread of AGE with Response = 0, that is NO; and Response=1, that is YES.","metadata":{}},{"cell_type":"code","source":"ax = sns.boxplot(data=mdata,y=mdata['Age'],x=mdata['Response'])","metadata":{"execution":{"iopub.status.busy":"2022-01-28T01:03:37.111184Z","iopub.execute_input":"2022-01-28T01:03:37.111536Z","iopub.status.idle":"2022-01-28T01:03:37.251424Z","shell.execute_reply.started":"2022-01-28T01:03:37.111494Z","shell.execute_reply":"2022-01-28T01:03:37.250616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- There does not seem to be a pattern between the Age of customers and their rate of acceptance. Both boxplots have similar medians and similar spread with almost same quantile ranges.\n- One interesting observation is the presence of customers as old as 130, which cannot be statistically negated.","metadata":{}},{"cell_type":"markdown","source":"### 11. The Chief Marketing specialist wants to visually see which Country has the most number of customers who accepted the last campaign. What is your approach? (1 point)","metadata":{}},{"cell_type":"markdown","source":"- First we subset mdata using loc operator with conditional on rows being Response==1.\n- Then, we group the data (countaining Country and Response) by 'Country' and aggregate it with sum() function. \n- We use reset_index() method to reset indices \n- Now we visualize it with a barplot.","metadata":{}},{"cell_type":"code","source":"data = mdata.loc[mdata['Response']==1,['Country','Response']]\ndata\n\nByCountry = data.groupby('Country').sum().reset_index()\nax = sns.barplot(data=ByCountry,x='Country',y='Response')","metadata":{"execution":{"iopub.status.busy":"2022-01-28T01:03:37.252754Z","iopub.execute_input":"2022-01-28T01:03:37.253048Z","iopub.status.idle":"2022-01-28T01:03:37.443885Z","shell.execute_reply.started":"2022-01-28T01:03:37.253005Z","shell.execute_reply":"2022-01-28T01:03:37.443014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Clearly the country **SP** has the most number of customers who accepted the last campaign.","metadata":{}},{"cell_type":"markdown","source":"### 12. Analyse visually and write your inferences about the relationship between the following:(1 point )\n- i) Total amount spent Vs Dependents. (Dependents=['Kidhome']+['Teenhome'])","metadata":{}},{"cell_type":"markdown","source":"- I use regplot.","metadata":{}},{"cell_type":"code","source":"Dependents = mdata['Kidhome']+mdata['Teenhome'] #numerical data\nax = sns.regplot(x=Dependents,y=mdata['Total_amount'])","metadata":{"execution":{"iopub.status.busy":"2022-01-28T01:03:37.445414Z","iopub.execute_input":"2022-01-28T01:03:37.445753Z","iopub.status.idle":"2022-01-28T01:03:37.819418Z","shell.execute_reply.started":"2022-01-28T01:03:37.445717Z","shell.execute_reply":"2022-01-28T01:03:37.818591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- But this is not a very nice chart. It deals with number of dependents as continuous\n- And there are only four possible values of 'Dependents'. \n- I would rather chart a bargraph.","metadata":{}},{"cell_type":"code","source":"ax = sns.barplot(x=Dependents,y=mdata['Total_amount'])\nax.set(xlabel='Number of Dependents')","metadata":{"execution":{"iopub.status.busy":"2022-01-28T01:03:37.820872Z","iopub.execute_input":"2022-01-28T01:03:37.821105Z","iopub.status.idle":"2022-01-28T01:03:38.105842Z","shell.execute_reply.started":"2022-01-28T01:03:37.821076Z","shell.execute_reply":"2022-01-28T01:03:38.10498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- ii) Total Purchases Vs Dependents.","metadata":{}},{"cell_type":"code","source":"ax=sns.barplot(x=Dependents,y=mdata['total_purchase'])\nax.set(xlabel='Number of Dependents')","metadata":{"execution":{"iopub.status.busy":"2022-01-28T01:03:38.107376Z","iopub.execute_input":"2022-01-28T01:03:38.107697Z","iopub.status.idle":"2022-01-28T01:03:38.401698Z","shell.execute_reply.started":"2022-01-28T01:03:38.107657Z","shell.execute_reply":"2022-01-28T01:03:38.400862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### inferences:\n- Customers with no dependents at home spend most.\n- This does not seem surprising looking at the products which they are buying and the trend of buy wines a lot.\n- In households with depedents, consumption of other goods like Tuition fees, Wardrobe etc increases.\n- There is a slight increment in total amount spent with dependents==3, because in that case, one can safely assume a few of them are TEEN and hence almost adults.\n- The trend of total_purchase is almost the same, and for the same reasons. The godds in concern are most freely purchased in households with no dependents given the financial constraints of bringing them up.\n- The spread of data (variance) in case of both with customers (dependents==3) is most. It can be explained that with dependents, their choices begin to dominate the purchase/expenditure, leading to a greater variance.","metadata":{}},{"cell_type":"markdown","source":"### 13.Perform Correlation Analysis and write your key inferences. (Hint:- visualise using an appropriate plot) (1 point)","metadata":{}},{"cell_type":"code","source":"#correlation analysis makes sense only in between Numerical data\n#extracting all numerical Attributes in a dummy dataframe\ndummy=mdata.loc[:,['Income','Kidhome','Teenhome','Recency','MntWines','MntFruits','MntMeatProducts','MntFishProducts','MntSweetProducts','MntGoldProds','NumDealsPurchases','NumWebPurchases','NumCatalogPurchases','NumStorePurchases','NumWebVisitsMonth','Age','Total_amount','total_purchase']]","metadata":{"execution":{"iopub.status.busy":"2022-01-28T01:03:38.402994Z","iopub.execute_input":"2022-01-28T01:03:38.404749Z","iopub.status.idle":"2022-01-28T01:03:38.411181Z","shell.execute_reply.started":"2022-01-28T01:03:38.404701Z","shell.execute_reply":"2022-01-28T01:03:38.410585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#making correlation matrix of the above dummy dataset using .corr() method\n#and feeding the correlation matrix into a heatmap\n\nax,figure=plt.subplots(figsize=(18,18))\nax=sns.heatmap(dummy.corr(),annot=True,)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T01:03:38.412266Z","iopub.execute_input":"2022-01-28T01:03:38.412657Z","iopub.status.idle":"2022-01-28T01:03:40.587457Z","shell.execute_reply.started":"2022-01-28T01:03:38.412599Z","shell.execute_reply":"2022-01-28T01:03:40.586856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#I prefer numbers over colors, so I will also use correlation matrix in its raw form to draw inferences\ndummy.corr()","metadata":{"execution":{"iopub.status.busy":"2022-01-28T01:03:40.588686Z","iopub.execute_input":"2022-01-28T01:03:40.588916Z","iopub.status.idle":"2022-01-28T01:03:40.625305Z","shell.execute_reply.started":"2022-01-28T01:03:40.588889Z","shell.execute_reply":"2022-01-28T01:03:40.624408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Inferences:\n- Income is greatly correlated to total purchase as well as total amount spent\n- Recency is an independent variable with almost no correlation with others. But I won't think about it much. And it is expected. There are too many factors a customer would take days to visit a store.\n- Amount spent on Gold has less correlation with Income. But with meat and wine it is significant (though still less than 0.7). People love to eat and enjoy rather than spend on gold. And they spend on Gold not so frequently.\n- There is a negative correlation between income and Purchases with discount (though not much). People don't care about discounts when income is high. They also don't spend time on website of the store if they earn a lot.\n- Age of the customer is not much correlated with any of the other attributes. It is expected. \n- Amount spent on different products is decently correlated with each other except Gold which is a luxury item.\n- There is a negative correlation of Number of Kids at home with almost all other attributes. They do affect life a lot.","metadata":{}},{"cell_type":"markdown","source":"### 14. Understand the Education background of the customers who complained in the last 2 years. State the Education background of the customers who have registered the most number of complaints. (Hint:- you can use appropriate) (1 point)","metadata":{}},{"cell_type":"code","source":"ComplaintsEd = mdata.loc[:,['Education','Complain']]\nComplaintsEd = ComplaintsEd.groupby('Education').sum().reset_index()\nax = sns.barplot(data=ComplaintsEd,x='Education',y='Complain')\nax.set(xlabel='Education Level',ylabel='Number of Complaints')","metadata":{"execution":{"iopub.status.busy":"2022-01-28T01:03:40.626751Z","iopub.execute_input":"2022-01-28T01:03:40.62708Z","iopub.status.idle":"2022-01-28T01:03:40.79471Z","shell.execute_reply.started":"2022-01-28T01:03:40.627039Z","shell.execute_reply":"2022-01-28T01:03:40.793948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As is clear from the barplot, those with **Graduation background** filed the most number of complaints.","metadata":{}},{"cell_type":"markdown","source":"### 15. Use features 'Total_amount_spent', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts' and, 'MntGoldProds' in x-axis and y-axis and plot the following plots. (2 points)\n- i) Plot a pairplot with hue as Response.\n- ii) Plot a pairplot with hue as Education.\n- iii) Plot a pairplot with hue as Marital Status and write your key observations.","metadata":{}},{"cell_type":"markdown","source":"i) Plot a pairplot with hue as Response.","metadata":{}},{"cell_type":"code","source":"ax = sns.pairplot(data=mdata, vars=['Total_amount','MntFruits','MntMeatProducts','MntFishProducts','MntSweetProducts','MntGoldProds'], hue='Response')","metadata":{"execution":{"iopub.status.busy":"2022-01-28T01:03:40.797831Z","iopub.execute_input":"2022-01-28T01:03:40.798072Z","iopub.status.idle":"2022-01-28T01:03:55.174593Z","shell.execute_reply.started":"2022-01-28T01:03:40.798043Z","shell.execute_reply":"2022-01-28T01:03:55.173659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ii) Plot a pairplot with hue as Education.","metadata":{}},{"cell_type":"code","source":"ax = sns.pairplot(data=mdata, vars=['Total_amount','MntFruits','MntMeatProducts','MntFishProducts','MntSweetProducts','MntGoldProds'], hue='Education')","metadata":{"execution":{"iopub.status.busy":"2022-01-28T01:03:55.175629Z","iopub.execute_input":"2022-01-28T01:03:55.175846Z","iopub.status.idle":"2022-01-28T01:04:12.262361Z","shell.execute_reply.started":"2022-01-28T01:03:55.175819Z","shell.execute_reply":"2022-01-28T01:04:12.261454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"iii) Plot a pairplot with hue as Marital Status and write your key observations.","metadata":{}},{"cell_type":"code","source":"ax = sns.pairplot(data=mdata, vars=['Total_amount','MntFruits','MntMeatProducts','MntFishProducts','MntSweetProducts','MntGoldProds'], hue='Marital_Status')","metadata":{"execution":{"iopub.status.busy":"2022-01-28T01:04:12.263537Z","iopub.execute_input":"2022-01-28T01:04:12.263809Z","iopub.status.idle":"2022-01-28T01:04:31.737802Z","shell.execute_reply.started":"2022-01-28T01:04:12.263777Z","shell.execute_reply":"2022-01-28T01:04:31.736945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ","metadata":{}}]}