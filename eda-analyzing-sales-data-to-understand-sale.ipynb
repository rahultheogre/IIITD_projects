{"cells":[{"source":"<a href=\"https://www.kaggle.com/rahultheogre/eda-analyzing-sales-data-to-understand-sale?scriptVersionId=85475112\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","id":"b6cddc1c","metadata":{"papermill":{"duration":0.028716,"end_time":"2022-01-17T18:43:30.764642","exception":false,"start_time":"2022-01-17T18:43:30.735926","status":"completed"},"tags":[]},"source":["### Dataset: Online_sales.csv\n","#### Domain: Retail\n","##### Objective: Analyzing sales data to understand sales trend"]},{"cell_type":"markdown","id":"b16acd18","metadata":{"papermill":{"duration":0.034118,"end_time":"2022-01-17T18:43:30.826567","exception":false,"start_time":"2022-01-17T18:43:30.792449","status":"completed"},"tags":[]},"source":["##### 1. Import necessary libraries and read the provided dataset (online_sales.csv) and check the top 5 and random 5 samples of the dataframe. (0.5 point)"]},{"cell_type":"markdown","id":"ceb859f0","metadata":{"papermill":{"duration":0.02692,"end_time":"2022-01-17T18:43:30.881085","exception":false,"start_time":"2022-01-17T18:43:30.854165","status":"completed"},"tags":[]},"source":["1. The \"online_sales.csv\" file is in the same folder the one in which Python_ProjectNo1 notebook file is.\n","2. head() method of Pandas DataFrame gives first five rows\n","3. sample() gives any 5 randome rows."]},{"cell_type":"code","execution_count":1,"id":"06e0b302","metadata":{"execution":{"iopub.execute_input":"2022-01-17T18:43:30.939873Z","iopub.status.busy":"2022-01-17T18:43:30.938676Z","iopub.status.idle":"2022-01-17T18:43:30.95323Z","shell.execute_reply":"2022-01-17T18:43:30.953887Z","shell.execute_reply.started":"2022-01-16T23:21:01.769495Z"},"papermill":{"duration":0.045851,"end_time":"2022-01-17T18:43:30.954274","exception":false,"start_time":"2022-01-17T18:43:30.908423","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/iiitd-project1/online_sales.csv\n"]}],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))"]},{"cell_type":"code","execution_count":2,"id":"2be5fd5b","metadata":{"execution":{"iopub.execute_input":"2022-01-17T18:43:31.017074Z","iopub.status.busy":"2022-01-17T18:43:31.016337Z","iopub.status.idle":"2022-01-17T18:43:31.575201Z","shell.execute_reply":"2022-01-17T18:43:31.574534Z","shell.execute_reply.started":"2022-01-16T23:21:01.786349Z"},"papermill":{"duration":0.592837,"end_time":"2022-01-17T18:43:31.575355","exception":false,"start_time":"2022-01-17T18:43:30.982518","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>InvoiceNo</th>\n","      <th>StockCode</th>\n","      <th>Description</th>\n","      <th>Quantity</th>\n","      <th>InvoiceDate</th>\n","      <th>UnitPrice</th>\n","      <th>CustomerID</th>\n","      <th>Country</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>536365</td>\n","      <td>85123A</td>\n","      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>\n","      <td>6</td>\n","      <td>12/1/10 8:26</td>\n","      <td>2.55</td>\n","      <td>17850.0</td>\n","      <td>United Kingdom</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>536365</td>\n","      <td>71053</td>\n","      <td>WHITE METAL LANTERN</td>\n","      <td>6</td>\n","      <td>12/1/10 8:26</td>\n","      <td>3.39</td>\n","      <td>17850.0</td>\n","      <td>United Kingdom</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>536365</td>\n","      <td>84406B</td>\n","      <td>CREAM CUPID HEARTS COAT HANGER</td>\n","      <td>8</td>\n","      <td>12/1/10 8:26</td>\n","      <td>2.75</td>\n","      <td>17850.0</td>\n","      <td>United Kingdom</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>536365</td>\n","      <td>84029G</td>\n","      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>\n","      <td>6</td>\n","      <td>12/1/10 8:26</td>\n","      <td>3.39</td>\n","      <td>17850.0</td>\n","      <td>United Kingdom</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>536365</td>\n","      <td>84029E</td>\n","      <td>RED WOOLLY HOTTIE WHITE HEART.</td>\n","      <td>6</td>\n","      <td>12/1/10 8:26</td>\n","      <td>3.39</td>\n","      <td>17850.0</td>\n","      <td>United Kingdom</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  InvoiceNo StockCode                          Description  Quantity  \\\n","0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n","1    536365     71053                  WHITE METAL LANTERN         6   \n","2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n","3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n","4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n","\n","    InvoiceDate  UnitPrice  CustomerID         Country  \n","0  12/1/10 8:26       2.55     17850.0  United Kingdom  \n","1  12/1/10 8:26       3.39     17850.0  United Kingdom  \n","2  12/1/10 8:26       2.75     17850.0  United Kingdom  \n","3  12/1/10 8:26       3.39     17850.0  United Kingdom  \n","4  12/1/10 8:26       3.39     17850.0  United Kingdom  "]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["\n","dataset = pd.read_csv(\"../input/iiitd-project1/online_sales.csv\")\n","\n","dataset.head()"]},{"cell_type":"code","execution_count":3,"id":"8718fcee","metadata":{"execution":{"iopub.execute_input":"2022-01-17T18:43:31.647033Z","iopub.status.busy":"2022-01-17T18:43:31.639893Z","iopub.status.idle":"2022-01-17T18:43:31.666207Z","shell.execute_reply":"2022-01-17T18:43:31.665542Z","shell.execute_reply.started":"2022-01-16T23:21:02.143004Z"},"papermill":{"duration":0.061899,"end_time":"2022-01-17T18:43:31.666376","exception":false,"start_time":"2022-01-17T18:43:31.604477","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>InvoiceNo</th>\n","      <th>StockCode</th>\n","      <th>Description</th>\n","      <th>Quantity</th>\n","      <th>InvoiceDate</th>\n","      <th>UnitPrice</th>\n","      <th>CustomerID</th>\n","      <th>Country</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>223588</th>\n","      <td>556484</td>\n","      <td>22326</td>\n","      <td>ROUND SNACK BOXES SET OF4 WOODLAND</td>\n","      <td>2</td>\n","      <td>6/12/11 13:17</td>\n","      <td>2.95</td>\n","      <td>16938.0</td>\n","      <td>United Kingdom</td>\n","    </tr>\n","    <tr>\n","      <th>231365</th>\n","      <td>557263</td>\n","      <td>23207</td>\n","      <td>LUNCH BAG ALPHABET DESIGN</td>\n","      <td>100</td>\n","      <td>6/19/11 11:08</td>\n","      <td>1.45</td>\n","      <td>14646.0</td>\n","      <td>Netherlands</td>\n","    </tr>\n","    <tr>\n","      <th>86280</th>\n","      <td>543543</td>\n","      <td>22722</td>\n","      <td>SET OF 6 SPICE TINS PANTRY DESIGN</td>\n","      <td>1</td>\n","      <td>2/9/11 15:33</td>\n","      <td>3.95</td>\n","      <td>17843.0</td>\n","      <td>United Kingdom</td>\n","    </tr>\n","    <tr>\n","      <th>33645</th>\n","      <td>539281</td>\n","      <td>22318</td>\n","      <td>FIVE HEART HANGING DECORATION</td>\n","      <td>6</td>\n","      <td>12/16/10 15:45</td>\n","      <td>2.95</td>\n","      <td>18176.0</td>\n","      <td>United Kingdom</td>\n","    </tr>\n","    <tr>\n","      <th>122500</th>\n","      <td>546877</td>\n","      <td>84946</td>\n","      <td>ANTIQUE SILVER TEA GLASS ETCHED</td>\n","      <td>24</td>\n","      <td>3/17/11 16:58</td>\n","      <td>1.25</td>\n","      <td>18210.0</td>\n","      <td>United Kingdom</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       InvoiceNo StockCode                          Description  Quantity  \\\n","223588    556484     22326  ROUND SNACK BOXES SET OF4 WOODLAND          2   \n","231365    557263     23207            LUNCH BAG ALPHABET DESIGN       100   \n","86280     543543     22722    SET OF 6 SPICE TINS PANTRY DESIGN         1   \n","33645     539281     22318        FIVE HEART HANGING DECORATION         6   \n","122500    546877     84946      ANTIQUE SILVER TEA GLASS ETCHED        24   \n","\n","           InvoiceDate  UnitPrice  CustomerID         Country  \n","223588   6/12/11 13:17       2.95     16938.0  United Kingdom  \n","231365   6/19/11 11:08       1.45     14646.0     Netherlands  \n","86280     2/9/11 15:33       3.95     17843.0  United Kingdom  \n","33645   12/16/10 15:45       2.95     18176.0  United Kingdom  \n","122500   3/17/11 16:58       1.25     18210.0  United Kingdom  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["dataset.sample(5)"]},{"cell_type":"markdown","id":"2496c463","metadata":{"papermill":{"duration":0.029098,"end_time":"2022-01-17T18:43:31.724512","exception":false,"start_time":"2022-01-17T18:43:31.695414","status":"completed"},"tags":[]},"source":["#### 2. Check info of the dataframe and write your observations. Comment on data types and shape of the dataset. (0.5 point)"]},{"cell_type":"code","execution_count":4,"id":"212827a4","metadata":{"execution":{"iopub.execute_input":"2022-01-17T18:43:31.787555Z","iopub.status.busy":"2022-01-17T18:43:31.786811Z","iopub.status.idle":"2022-01-17T18:43:31.945148Z","shell.execute_reply":"2022-01-17T18:43:31.945777Z","shell.execute_reply.started":"2022-01-16T23:21:02.166214Z"},"papermill":{"duration":0.191058,"end_time":"2022-01-17T18:43:31.945962","exception":false,"start_time":"2022-01-17T18:43:31.754904","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 240007 entries, 0 to 240006\n","Data columns (total 8 columns):\n"," #   Column       Non-Null Count   Dtype  \n","---  ------       --------------   -----  \n"," 0   InvoiceNo    240007 non-null  object \n"," 1   StockCode    240007 non-null  object \n"," 2   Description  239106 non-null  object \n"," 3   Quantity     240007 non-null  int64  \n"," 4   InvoiceDate  240007 non-null  object \n"," 5   UnitPrice    240007 non-null  float64\n"," 6   CustomerID   172782 non-null  float64\n"," 7   Country      240007 non-null  object \n","dtypes: float64(2), int64(1), object(5)\n","memory usage: 14.6+ MB\n"]},{"data":{"text/plain":["(240007, 8)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["#info method gives a summary statistics of the dataframe\n","dataset.info()\n","dataset.shape"]},{"cell_type":"markdown","id":"a0a828bb","metadata":{"papermill":{"duration":0.029242,"end_time":"2022-01-17T18:43:32.004769","exception":false,"start_time":"2022-01-17T18:43:31.975527","status":"completed"},"tags":[]},"source":["###### Comments\n","1. It is a dataset of online sales of a firm. \n","2. There are 8 columns, and hence 8 variables through which the data is viewed.\n","3. There are 240007 rows. The shape is (240007, 8). It is a fairly large dataset.\n","4. InvoiceNo is an object (str or mixed), which could have come as a surprise, because we would expect it to be numeric. But one, we don't want any kind of accidental change in the InvoiceNo. And two, even though all the sample values seem numeric in the current dataset, we can have alphanumeric/numeric characters in an InvoiceNo.\n","5. CustomerID is a float64 which seems weird. It could easily have been int64 like Quantity. It occupies more memory space than required.\n","6. InvoiceDate is an object, which was expected. We often deal with str inputs in columns of datetimes. We would have to convert it into datetime when time comes.  \n","7. There are many null values in the dataset, specially the CustomerIDs. We may have to drop them. Dropping them won't affect our analysis much, because we have a lot of rows."]},{"cell_type":"markdown","id":"1108efff","metadata":{"papermill":{"duration":0.031034,"end_time":"2022-01-17T18:43:32.065436","exception":false,"start_time":"2022-01-17T18:43:32.034402","status":"completed"},"tags":[]},"source":["#### 3. Check for null values and report the percentage of null values of each column.And drop the rows having null values in it. (1 point)"]},{"cell_type":"markdown","id":"8e856532","metadata":{"papermill":{"duration":0.029736,"end_time":"2022-01-17T18:43:32.124803","exception":false,"start_time":"2022-01-17T18:43:32.095067","status":"completed"},"tags":[]},"source":["\n","- STEPS:\n","1. Use isna() method to check for null values. It returns a mask of bool values for each element in dataset that indicates whether an element is an NA value or not. Each NaN is booled as True i.e. 1.\n","2. Apply sum() method to the above mask to return a Series of sums of 1's for each column.\n","3. Convert the Series of [columns, sums of NaNs] into a DataFrame using pd.DataFrame() for better visualisation and manipulation. Call this new dataframe as d_null.\n","4. Use columns attribute to name the one column d_null has as NoOfNull.\n","5. Use apply method to add a new column(axis = 1) called PercentNull. \n","6. In apply(), use lambda function to perform the required operation on each instance of NoOfNull \n","7. Print d_null. That would report the percentage of null values of each column of the dataset"]},{"cell_type":"code","execution_count":5,"id":"eeaff534","metadata":{"execution":{"iopub.execute_input":"2022-01-17T18:43:32.3221Z","iopub.status.busy":"2022-01-17T18:43:32.321319Z","iopub.status.idle":"2022-01-17T18:43:32.333842Z","shell.execute_reply":"2022-01-17T18:43:32.33307Z","shell.execute_reply.started":"2022-01-16T23:21:02.32571Z"},"papermill":{"duration":0.179144,"end_time":"2022-01-17T18:43:32.333998","exception":false,"start_time":"2022-01-17T18:43:32.154854","status":"completed"},"scrolled":true,"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["             NoOfNull  PercentNull\n","InvoiceNo           0     0.000000\n","StockCode           0     0.000000\n","Description       901     0.375406\n","Quantity            0     0.000000\n","InvoiceDate         0     0.000000\n","UnitPrice           0     0.000000\n","CustomerID      67225    28.009600\n","Country             0     0.000000\n"]}],"source":["d_null = dataset.isna().sum() #Steps 1,2\n","\n","d_null = pd.DataFrame(d_null) #Step 3\n","\n","d_null.columns = ['NoOfNull'] #Step 4\n","\n","d_null['PercentNull'] = d_null.apply(lambda row: (row.NoOfNull/len(dataset))*100 , axis = 1) #step 5,6\n","\n","print(d_null) #Step 7"]},{"cell_type":"markdown","id":"9117b559","metadata":{"papermill":{"duration":0.029412,"end_time":"2022-01-17T18:43:32.39335","exception":false,"start_time":"2022-01-17T18:43:32.363938","status":"completed"},"tags":[]},"source":["###### To drop the rows having null values in it\n","STEPS:\n","1. use dropna() method to drop all NaN values.\n","2. use info() method to display the change\n","- NOTE: I am making a new DataFrame for this question. In Practice, I would have altered the original dataset with reassignment. But I want the examiners to be able to come back and check, and any alteration in dataset is permanent. "]},{"cell_type":"code","execution_count":6,"id":"577f1f18","metadata":{"execution":{"iopub.execute_input":"2022-01-17T18:43:32.591504Z","iopub.status.busy":"2022-01-17T18:43:32.590232Z","iopub.status.idle":"2022-01-17T18:43:32.720389Z","shell.execute_reply":"2022-01-17T18:43:32.71964Z","shell.execute_reply.started":"2022-01-16T23:21:02.469956Z"},"papermill":{"duration":0.297049,"end_time":"2022-01-17T18:43:32.720559","exception":false,"start_time":"2022-01-17T18:43:32.42351","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 172782 entries, 0 to 240006\n","Data columns (total 8 columns):\n"," #   Column       Non-Null Count   Dtype  \n","---  ------       --------------   -----  \n"," 0   InvoiceNo    172782 non-null  object \n"," 1   StockCode    172782 non-null  object \n"," 2   Description  172782 non-null  object \n"," 3   Quantity     172782 non-null  int64  \n"," 4   InvoiceDate  172782 non-null  object \n"," 5   UnitPrice    172782 non-null  float64\n"," 6   CustomerID   172782 non-null  float64\n"," 7   Country      172782 non-null  object \n","dtypes: float64(2), int64(1), object(5)\n","memory usage: 11.9+ MB\n"]}],"source":["dataset_NoNull = dataset.dropna() #Step 1\n","dataset_NoNull.info() #Step 2"]},{"cell_type":"markdown","id":"6b7cca26","metadata":{"papermill":{"duration":0.030895,"end_time":"2022-01-17T18:43:32.781852","exception":false,"start_time":"2022-01-17T18:43:32.750957","status":"completed"},"tags":[]},"source":["##### 5. Drop the instances having quantity less than zero. (1 point) (Note:- refer to the ‘Quantity’ feature)"]},{"cell_type":"markdown","id":"16a4472e","metadata":{"papermill":{"duration":0.030388,"end_time":"2022-01-17T18:43:32.843351","exception":false,"start_time":"2022-01-17T18:43:32.812963","status":"completed"},"tags":[]},"source":["###### NOTE: I am solving Q 5 before Q 4, because we don't want negative Quantity values in a dataset when performing a statistical analysis on it.\n","\n","- STEPS\n","1. Get the indices with negative Quantity instances with by\n","    - selecting the rows where Quantity<0, and\n","    - selecting the indices of those rows with index attribute\n","    - Store the indices in i\n","2. Use drop() method to remove the selected indices contained in i. Have inplace parameter as False so the original dataset does not change.\n","3. clean_data is the resultant dataset which has no null values and no rows with negative Quantity values. We will use this dataset from now on."]},{"cell_type":"code","execution_count":7,"id":"bf4bd94c","metadata":{"execution":{"iopub.execute_input":"2022-01-17T18:43:32.917658Z","iopub.status.busy":"2022-01-17T18:43:32.916932Z","iopub.status.idle":"2022-01-17T18:43:33.047325Z","shell.execute_reply":"2022-01-17T18:43:33.046563Z","shell.execute_reply.started":"2022-01-16T23:21:02.725007Z"},"papermill":{"duration":0.173533,"end_time":"2022-01-17T18:43:33.04749","exception":false,"start_time":"2022-01-17T18:43:32.873957","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 168675 entries, 0 to 240006\n","Data columns (total 8 columns):\n"," #   Column       Non-Null Count   Dtype  \n","---  ------       --------------   -----  \n"," 0   InvoiceNo    168675 non-null  object \n"," 1   StockCode    168675 non-null  object \n"," 2   Description  168675 non-null  object \n"," 3   Quantity     168675 non-null  int64  \n"," 4   InvoiceDate  168675 non-null  object \n"," 5   UnitPrice    168675 non-null  float64\n"," 6   CustomerID   168675 non-null  float64\n"," 7   Country      168675 non-null  object \n","dtypes: float64(2), int64(1), object(5)\n","memory usage: 11.6+ MB\n"]}],"source":["i = dataset_NoNull[dataset_NoNull['Quantity'] < 0].index #Step 1\n","\n","clean_data = dataset_NoNull.drop(i, axis = 'rows', inplace = False) #Step 2\n","\n","clean_data.info() #3 "]},{"cell_type":"markdown","id":"366171f9","metadata":{"papermill":{"duration":0.030411,"end_time":"2022-01-17T18:43:33.108631","exception":false,"start_time":"2022-01-17T18:43:33.07822","status":"completed"},"tags":[]},"source":["#### 4. Check the statistical summary of the dataset. (Use inbuilt functions) (0.5 point)"]},{"cell_type":"markdown","id":"c0a1aac1","metadata":{"papermill":{"duration":0.031909,"end_time":"2022-01-17T18:43:33.171653","exception":false,"start_time":"2022-01-17T18:43:33.139744","status":"completed"},"tags":[]},"source":["1. I will work on clean_data, which is what we should ideally work with. That is why I decided to solve Q 5 first.\n","2. REASON (IMPORTANT): \n","- About 28% of CustomerId values are NaN. We have to take them as bogus as every Invoice should have a CustomerId. How can a record have an InvoiceNo but no CustomerId? \n","- Also, Quantity vaues cannot be negative. So, bogus data. Description does not matter, as it seems  optional. But a very small percentage of data loss would be there (0.37% bogus data). And with so many entries at hand, we can handle that data loss. "]},{"cell_type":"code","execution_count":8,"id":"2c2d2af1","metadata":{"execution":{"iopub.execute_input":"2022-01-17T18:43:33.24417Z","iopub.status.busy":"2022-01-17T18:43:33.24344Z","iopub.status.idle":"2022-01-17T18:43:33.280814Z","shell.execute_reply":"2022-01-17T18:43:33.279796Z","shell.execute_reply.started":"2022-01-16T23:21:02.858233Z"},"papermill":{"duration":0.078931,"end_time":"2022-01-17T18:43:33.280993","exception":false,"start_time":"2022-01-17T18:43:33.202062","status":"completed"},"scrolled":true,"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Quantity</th>\n","      <th>UnitPrice</th>\n","      <th>CustomerID</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>172782.000000</td>\n","      <td>172782.000000</td>\n","      <td>172782.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>12.244835</td>\n","      <td>3.793566</td>\n","      <td>15274.819941</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>257.898235</td>\n","      <td>101.069930</td>\n","      <td>1725.093177</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>-74215.000000</td>\n","      <td>0.000000</td>\n","      <td>12346.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>2.000000</td>\n","      <td>1.250000</td>\n","      <td>13842.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>5.000000</td>\n","      <td>1.950000</td>\n","      <td>15132.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>12.000000</td>\n","      <td>3.750000</td>\n","      <td>16814.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>74215.000000</td>\n","      <td>38970.000000</td>\n","      <td>18287.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            Quantity      UnitPrice     CustomerID\n","count  172782.000000  172782.000000  172782.000000\n","mean       12.244835       3.793566   15274.819941\n","std       257.898235     101.069930    1725.093177\n","min    -74215.000000       0.000000   12346.000000\n","25%         2.000000       1.250000   13842.000000\n","50%         5.000000       1.950000   15132.000000\n","75%        12.000000       3.750000   16814.000000\n","max     74215.000000   38970.000000   18287.000000"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["dataset_NoNull.describe() \n","#Here min value of Quantity is -74215, which is inadmissible"]},{"cell_type":"markdown","id":"cce55ff8","metadata":{"papermill":{"duration":0.030859,"end_time":"2022-01-17T18:43:33.343458","exception":false,"start_time":"2022-01-17T18:43:33.312599","status":"completed"},"tags":[]},"source":["#### Solution to Q 4\n","\n","- STEPS\n","1. Use descibe() method to give basic descriptive statistical summary. It chooses only those columns which have numeric values as instances.\n","2. Note: describe() on clean_data gives us more valid values. Case in point: min(Quantity) is now 1"]},{"cell_type":"code","execution_count":9,"id":"b93949f4","metadata":{"execution":{"iopub.execute_input":"2022-01-17T18:43:33.419677Z","iopub.status.busy":"2022-01-17T18:43:33.415627Z","iopub.status.idle":"2022-01-17T18:43:33.450519Z","shell.execute_reply":"2022-01-17T18:43:33.449905Z","shell.execute_reply.started":"2022-01-16T23:21:02.89605Z"},"papermill":{"duration":0.075338,"end_time":"2022-01-17T18:43:33.450669","exception":false,"start_time":"2022-01-17T18:43:33.375331","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Quantity</th>\n","      <th>UnitPrice</th>\n","      <th>CustomerID</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>168675.000000</td>\n","      <td>168675.000000</td>\n","      <td>168675.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>13.302001</td>\n","      <td>3.285819</td>\n","      <td>15282.751736</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>186.458144</td>\n","      <td>24.203825</td>\n","      <td>1724.910408</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>12346.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>2.000000</td>\n","      <td>1.250000</td>\n","      <td>13859.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>6.000000</td>\n","      <td>1.950000</td>\n","      <td>15147.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>12.000000</td>\n","      <td>3.750000</td>\n","      <td>16818.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>74215.000000</td>\n","      <td>8142.750000</td>\n","      <td>18287.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            Quantity      UnitPrice     CustomerID\n","count  168675.000000  168675.000000  168675.000000\n","mean       13.302001       3.285819   15282.751736\n","std       186.458144      24.203825    1724.910408\n","min         1.000000       0.000000   12346.000000\n","25%         2.000000       1.250000   13859.000000\n","50%         6.000000       1.950000   15147.000000\n","75%        12.000000       3.750000   16818.000000\n","max     74215.000000    8142.750000   18287.000000"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["clean_data.describe() #Step 1"]},{"cell_type":"markdown","id":"77ae5bc5","metadata":{"papermill":{"duration":0.031396,"end_time":"2022-01-17T18:43:33.514319","exception":false,"start_time":"2022-01-17T18:43:33.482923","status":"completed"},"tags":[]},"source":["##### 6. Check unique values of the country and report the name of the country that has the highest number of instances/rows. (0.5 point)"]},{"cell_type":"markdown","id":"7dc76c92","metadata":{"papermill":{"duration":0.030972,"end_time":"2022-01-17T18:43:33.576559","exception":false,"start_time":"2022-01-17T18:43:33.545587","status":"completed"},"tags":[]},"source":["###### Unique values of the country\n","- STEPS:\n","1. Extract the Country column using dot operator from the clean_data as a Series\n","2. Apply unique() method to it to have only unique values in an array unique_values\n","3. Print to give out Unique values of the country. Use * unpacking operator to get comma separated values."]},{"cell_type":"code","execution_count":10,"id":"2febee87","metadata":{"execution":{"iopub.execute_input":"2022-01-17T18:43:33.656925Z","iopub.status.busy":"2022-01-17T18:43:33.656204Z","iopub.status.idle":"2022-01-17T18:43:33.669064Z","shell.execute_reply":"2022-01-17T18:43:33.668138Z","shell.execute_reply.started":"2022-01-16T23:21:02.929801Z"},"papermill":{"duration":0.061264,"end_time":"2022-01-17T18:43:33.669296","exception":false,"start_time":"2022-01-17T18:43:33.608032","status":"completed"},"scrolled":true,"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Unique values of the country in the dataset are:\n","\n","United Kingdom, France, Australia, Netherlands, Germany, Norway, EIRE, Switzerland, Spain, Poland, Portugal, Italy, Belgium, Lithuania, Japan, Iceland, Channel Islands, Denmark, Cyprus, Sweden, Finland, Austria, Greece, Singapore, Lebanon, United Arab Emirates, Israel, Saudi Arabia, Czech Republic, Canada, Unspecified, Brazil, USA, European Community, Bahrain, Malta, Unit\n"]}],"source":["unique_values = clean_data.Country.unique() #Step 1,2\n","\n","print(\"Unique values of the country in the dataset are:\\n\")\n","print(*unique_values, sep = ', ') #Step 3"]},{"cell_type":"markdown","id":"8c778c19","metadata":{"papermill":{"duration":0.031572,"end_time":"2022-01-17T18:43:33.733208","exception":false,"start_time":"2022-01-17T18:43:33.701636","status":"completed"},"tags":[]},"source":["###### Report the name of the country with highest number of instances.\n","- STEPS\n","1. Group the dataset according to Country column using groupby method \n","2. Aggregate by count() method choosing any column (all will give the same). I choose Description. It will give us a Pandas Series.\n","3. Convert the resultant Series into a dictionary dict1 using to_dict() Series method\n","4. Use lambda in max() function to iterate through each value of dict, and get the key (country) with maximum value. Print the result."]},{"cell_type":"code","execution_count":11,"id":"7056ab78","metadata":{"execution":{"iopub.execute_input":"2022-01-17T18:43:33.804668Z","iopub.status.busy":"2022-01-17T18:43:33.803526Z","iopub.status.idle":"2022-01-17T18:43:33.922008Z","shell.execute_reply":"2022-01-17T18:43:33.921329Z","shell.execute_reply.started":"2022-01-16T23:21:02.955586Z"},"papermill":{"duration":0.156592,"end_time":"2022-01-17T18:43:33.922185","exception":false,"start_time":"2022-01-17T18:43:33.765593","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["The country with highest number of instances is: United Kingdom\n"]}],"source":["dict1 = clean_data.groupby('Country').count().Description.to_dict() #Steps 1,2,3\n","\n","print(f\"The country with highest number of instances is: {max(dict1, key = lambda x: dict1[x])}\") #Step 4"]},{"cell_type":"markdown","id":"c6063a51","metadata":{"papermill":{"duration":0.032903,"end_time":"2022-01-17T18:43:33.989611","exception":false,"start_time":"2022-01-17T18:43:33.956708","status":"completed"},"tags":[]},"source":["##### 7. Create a new column with the name as ‘sales’ having total sales. The total sales is defined as Quantity*UnitPrice. (1 point)b"]},{"cell_type":"markdown","id":"9a6d7387","metadata":{"papermill":{"duration":0.03315,"end_time":"2022-01-17T18:43:34.055789","exception":false,"start_time":"2022-01-17T18:43:34.022639","status":"completed"},"tags":[]},"source":["STEPS:\n","1. Add a column with Index operator.\n","2. Assign it values using list comprehension\n","3. In list comprehension, zip two variables x and y, corresponding to values in columns Quantity and Price and get the result x*y assigned to new column"]},{"cell_type":"code","execution_count":12,"id":"fa508f6b","metadata":{"execution":{"iopub.execute_input":"2022-01-17T18:43:34.135302Z","iopub.status.busy":"2022-01-17T18:43:34.129941Z","iopub.status.idle":"2022-01-17T18:43:34.246111Z","shell.execute_reply":"2022-01-17T18:43:34.245547Z","shell.execute_reply.started":"2022-01-16T23:21:03.075962Z"},"papermill":{"duration":0.157862,"end_time":"2022-01-17T18:43:34.246293","exception":false,"start_time":"2022-01-17T18:43:34.088431","status":"completed"},"scrolled":true,"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>InvoiceNo</th>\n","      <th>StockCode</th>\n","      <th>Description</th>\n","      <th>Quantity</th>\n","      <th>InvoiceDate</th>\n","      <th>UnitPrice</th>\n","      <th>CustomerID</th>\n","      <th>Country</th>\n","      <th>sales</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>536365</td>\n","      <td>85123A</td>\n","      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>\n","      <td>6</td>\n","      <td>12/1/10 8:26</td>\n","      <td>2.55</td>\n","      <td>17850.0</td>\n","      <td>United Kingdom</td>\n","      <td>15.30</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>536365</td>\n","      <td>71053</td>\n","      <td>WHITE METAL LANTERN</td>\n","      <td>6</td>\n","      <td>12/1/10 8:26</td>\n","      <td>3.39</td>\n","      <td>17850.0</td>\n","      <td>United Kingdom</td>\n","      <td>20.34</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>536365</td>\n","      <td>84406B</td>\n","      <td>CREAM CUPID HEARTS COAT HANGER</td>\n","      <td>8</td>\n","      <td>12/1/10 8:26</td>\n","      <td>2.75</td>\n","      <td>17850.0</td>\n","      <td>United Kingdom</td>\n","      <td>22.00</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>536365</td>\n","      <td>84029G</td>\n","      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>\n","      <td>6</td>\n","      <td>12/1/10 8:26</td>\n","      <td>3.39</td>\n","      <td>17850.0</td>\n","      <td>United Kingdom</td>\n","      <td>20.34</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>536365</td>\n","      <td>84029E</td>\n","      <td>RED WOOLLY HOTTIE WHITE HEART.</td>\n","      <td>6</td>\n","      <td>12/1/10 8:26</td>\n","      <td>3.39</td>\n","      <td>17850.0</td>\n","      <td>United Kingdom</td>\n","      <td>20.34</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  InvoiceNo StockCode                          Description  Quantity  \\\n","0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n","1    536365     71053                  WHITE METAL LANTERN         6   \n","2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n","3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n","4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n","\n","    InvoiceDate  UnitPrice  CustomerID         Country  sales  \n","0  12/1/10 8:26       2.55     17850.0  United Kingdom  15.30  \n","1  12/1/10 8:26       3.39     17850.0  United Kingdom  20.34  \n","2  12/1/10 8:26       2.75     17850.0  United Kingdom  22.00  \n","3  12/1/10 8:26       3.39     17850.0  United Kingdom  20.34  \n","4  12/1/10 8:26       3.39     17850.0  United Kingdom  20.34  "]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["clean_data['sales'] = [x*y for (x,y) in zip(clean_data['Quantity'],clean_data['UnitPrice'])] #Steps 1,2,3\n","\n","clean_data.head()"]},{"cell_type":"markdown","id":"060473d6","metadata":{"papermill":{"duration":0.03244,"end_time":"2022-01-17T18:43:34.31161","exception":false,"start_time":"2022-01-17T18:43:34.27917","status":"completed"},"tags":[]},"source":["##### 8. Report the top 5 countries in terms of sales. (2 points)"]},{"cell_type":"markdown","id":"c822bdef","metadata":{"papermill":{"duration":0.032647,"end_time":"2022-01-17T18:43:34.377262","exception":false,"start_time":"2022-01-17T18:43:34.344615","status":"completed"},"tags":[]},"source":["###### a. Considering the size of the sales\n","- STEPS:\n","1. Group clean_data by Country using groupby method. Groups attribute is like dictionary whose keys are the computed unique groups and corresponding values being the axis labels belonging to each group. \n","2. Aggregate the resulting group with sum()\n","3. Extract 'sales' column by using dot operator over the aggregate.Now we will have a Series.\n","4. Sort the Series by value using sort_values() object. Make ascending attribute as False to sort in descending form.\n","5. Apply index operator to the sorted Series to extract first five index elements, which are country names."]},{"cell_type":"code","execution_count":13,"id":"9b05a10a","metadata":{"execution":{"iopub.execute_input":"2022-01-17T18:43:34.451262Z","iopub.status.busy":"2022-01-17T18:43:34.450542Z","iopub.status.idle":"2022-01-17T18:43:34.498692Z","shell.execute_reply":"2022-01-17T18:43:34.49704Z","shell.execute_reply.started":"2022-01-16T23:21:03.19945Z"},"papermill":{"duration":0.087865,"end_time":"2022-01-17T18:43:34.498942","exception":false,"start_time":"2022-01-17T18:43:34.411077","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Top five countries in terms of sales size are:\n","United Kingdom, Netherlands, Germany, EIRE, France\n"]}],"source":["by_sales_size = clean_data.groupby('Country').sum().sales.sort_values(ascending = False).index[0:5] #Steps 1,2,3,4, 5\n","\n","print(\"Top five countries in terms of sales size are:\")\n","print(*by_sales_size, sep= ', ')"]},{"cell_type":"markdown","id":"c4435fe0","metadata":{"papermill":{"duration":0.034365,"end_time":"2022-01-17T18:43:34.568467","exception":false,"start_time":"2022-01-17T18:43:34.534102","status":"completed"},"tags":[]},"source":["###### b. Consider the mean value of sales.\n","- STEPS:\n","1. Repeat all the steps as in 8(a) except for one change. Aggregate with mean() function instead of sum()."]},{"cell_type":"code","execution_count":14,"id":"34151d34","metadata":{"execution":{"iopub.execute_input":"2022-01-17T18:43:34.653547Z","iopub.status.busy":"2022-01-17T18:43:34.647762Z","iopub.status.idle":"2022-01-17T18:43:34.684824Z","shell.execute_reply":"2022-01-17T18:43:34.684166Z","shell.execute_reply.started":"2022-01-16T23:21:03.24903Z"},"papermill":{"duration":0.083135,"end_time":"2022-01-17T18:43:34.684988","exception":false,"start_time":"2022-01-17T18:43:34.601853","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Top five countries in terms of mean sales are:\n","Australia, Netherlands, Japan, Singapore, Sweden\n"]}],"source":["by_sales_mean = clean_data.groupby('Country').mean().sales.sort_values(ascending = False).index[0:5] \n","\n","print(\"Top five countries in terms of mean sales are:\")\n","print(*by_sales_mean, sep= ', ')"]},{"cell_type":"markdown","id":"28d66e60","metadata":{"papermill":{"duration":0.033728,"end_time":"2022-01-17T18:43:34.75328","exception":false,"start_time":"2022-01-17T18:43:34.719552","status":"completed"},"tags":[]},"source":["##### 9. Report the top 5 products which bring the highest sales. Use StockCode for product information. (1 point)"]},{"cell_type":"markdown","id":"bfe6839a","metadata":{"papermill":{"duration":0.033435,"end_time":"2022-01-17T18:43:34.821724","exception":false,"start_time":"2022-01-17T18:43:34.788289","status":"completed"},"tags":[]},"source":["- STEPS:\n","1. Use is_unique attribute on the Series clean_data.StockCode to check if the column has unique values. It turns out to be False. So we have to group clean_data by StockCode first. \n","2. Group clean_data by 'StockCode' using groupby method. And aggregate the resulting group with sum().\n","3. Extract 'sales' column by using dot operator over the aggregate. Now we will have a Series.\n","4. Sort the Series by value using sort_values() object. Make ascending attribute as False to sort in descending order.\n","5. Apply index operator to the sorted Series to extract first five index elements, which are Stock codes for top 4 products bringing in highest sales. "]},{"cell_type":"code","execution_count":15,"id":"9be121e1","metadata":{"execution":{"iopub.execute_input":"2022-01-17T18:43:34.91609Z","iopub.status.busy":"2022-01-17T18:43:34.914955Z","iopub.status.idle":"2022-01-17T18:43:34.940276Z","shell.execute_reply":"2022-01-17T18:43:34.939387Z","shell.execute_reply.started":"2022-01-16T23:21:03.295147Z"},"papermill":{"duration":0.0856,"end_time":"2022-01-17T18:43:34.940475","exception":false,"start_time":"2022-01-17T18:43:34.854875","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Top five products bringing the highest sales have the StockCodes as:\n","22423, 23166, 85123A, 22502, 47566\n"]}],"source":["top_5_products = clean_data.groupby('StockCode').sum().sales.sort_values(ascending = False).index[0:5] #Step 2,3,4,5\n","\n","print(\"Top five products bringing the highest sales have the StockCodes as:\")\n","print(*top_5_products, sep= ', ')"]},{"cell_type":"markdown","id":"a57301cc","metadata":{"papermill":{"duration":0.033711,"end_time":"2022-01-17T18:43:35.008704","exception":false,"start_time":"2022-01-17T18:43:34.974993","status":"completed"},"tags":[]},"source":["##### NOTE:\n","I tried fetching 'Description' values of corresponding 'StockCode' values. They are 'WHITE HANGING HEART T-LIGHT HOLDER', 'PICNIC BASKET WICKER SMALL','REGENCY CAKESTAND 3 TIER', 'PARTY BUNTING' 'MEDIUM CERAMIC TOP STORAGE JAR', 'PICNIC BASKET WICKER 60 PIECES'.\n","\n","I used the following code:\n","import numpy as np\n","top_5_p = clean_data.iloc[np.where(clean_data.StockCode.isin(top_5_products))].Description.unique()\n","top_5_p\n","\n","Clearly on of the StockCode values relates to two Description values, most probably 'PICNIC BASKET WICKER SMALL' and 'PICNIC BASKET WICKER 60 PIECES'. So, I left the result to mentioning StockCodes."]},{"cell_type":"markdown","id":"fff53218","metadata":{"papermill":{"duration":0.033445,"end_time":"2022-01-17T18:43:35.0759","exception":false,"start_time":"2022-01-17T18:43:35.042455","status":"completed"},"tags":[]},"source":["##### 10. Convert the ‘InvoiceDate’ into a date format and report the month on which the maximum sales occur? (2 points)"]},{"cell_type":"markdown","id":"e4969aaf","metadata":{"papermill":{"duration":0.033759,"end_time":"2022-01-17T18:43:35.143553","exception":false,"start_time":"2022-01-17T18:43:35.109794","status":"completed"},"tags":[]},"source":["###### Convert the ‘InvoiceDate’ into a date format\n","- STEPS:\n","1. Use to_datetime() method over the 'InvoiceDate' column of clean_dataset "]},{"cell_type":"code","execution_count":16,"id":"ce62c161","metadata":{"execution":{"iopub.execute_input":"2022-01-17T18:43:35.220718Z","iopub.status.busy":"2022-01-17T18:43:35.219732Z","iopub.status.idle":"2022-01-17T18:43:36.056032Z","shell.execute_reply":"2022-01-17T18:43:36.055389Z","shell.execute_reply.started":"2022-01-16T23:21:03.346733Z"},"papermill":{"duration":0.878954,"end_time":"2022-01-17T18:43:36.056229","exception":false,"start_time":"2022-01-17T18:43:35.177275","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["The object type of column 'InvoiceDate' now convert into date format i.e. datetime64[ns]\n"]}],"source":["clean_data['InvoiceDate'] = pd.to_datetime(clean_data['InvoiceDate'])\n","print(f\"The object type of column 'InvoiceDate' now convert into date format i.e. {clean_data['InvoiceDate'].dtypes}\")"]},{"cell_type":"markdown","id":"7cc92532","metadata":{"papermill":{"duration":0.033667,"end_time":"2022-01-17T18:43:36.124073","exception":false,"start_time":"2022-01-17T18:43:36.090406","status":"completed"},"tags":[]},"source":["##### report the month on which the maximum sales occur\n","STEPS:\n","1. Create a new column 'month' from 'InvoiceDate' using DatetimeIndex.strftime() method.\n","    - DatetimeIndex.strftime() gives out an Index of string values of a format supplied to it.\n","    - Put in %B as parameter to force out full month name. \n","2. Group the dataset by 'month' and Aggregate with sum() and save the dataframe in month_max.\n","3. Extract 'sales' from month_max using dot operator. Now it becomes a Pandas Series.\n","4. Sort the values in the Series of (months,sales). In descending order because we need the month with maximum sales.\n","5. Use Index operator on the ordered Series to get the first value- which is what we were after."]},{"cell_type":"code","execution_count":17,"id":"a5b97edc","metadata":{"execution":{"iopub.execute_input":"2022-01-17T18:43:36.197442Z","iopub.status.busy":"2022-01-17T18:43:36.196739Z","iopub.status.idle":"2022-01-17T18:43:37.525212Z","shell.execute_reply":"2022-01-17T18:43:37.524541Z","shell.execute_reply.started":"2022-01-16T23:21:04.170846Z"},"papermill":{"duration":1.365892,"end_time":"2022-01-17T18:43:37.5254","exception":false,"start_time":"2022-01-17T18:43:36.159508","status":"completed"},"scrolled":true,"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["The month on which maximum sales occur is May\n"]}],"source":["clean_data['month'] = pd.DatetimeIndex(clean_data['InvoiceDate']).strftime(\"%B\") #Step 1\n","\n","month_max = clean_data.groupby('month').sum().sales.sort_values(ascending = False).index[0] #Steps 2,3,4,5\n","\n","print(f\"The month on which maximum sales occur is {month_max}\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":18.368245,"end_time":"2022-01-17T18:43:38.273264","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-01-17T18:43:19.905019","version":"2.3.3"}},"nbformat":4,"nbformat_minor":5}