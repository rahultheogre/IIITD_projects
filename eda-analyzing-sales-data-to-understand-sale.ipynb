{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/rahultheogre/eda-analyzing-sales-data-to-understand-sale?scriptVersionId=85406340\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","source":"# PROJECT 1  \n## Name : Rahul Sharma","metadata":{}},{"cell_type":"markdown","source":"### Part - I (10 Points)\n##### 1. Answer the following questions. (2 points)","metadata":{}},{"cell_type":"markdown","source":"###### a. Given the string 'great', use an appropriate index command that returns 'a' from the string. Given s = ‘great’. (0.5 point) Expected output: ‘a'","metadata":{}},{"cell_type":"markdown","source":"1. Python is zero indexing language. Index position of 'a' is 3. \n2. So we insert 3 in the indexing operator to get 'a'","metadata":{}},{"cell_type":"code","source":"s = \"great\"\n\ns[3]","metadata":{"execution":{"iopub.status.busy":"2022-01-16T23:20:10.730406Z","iopub.execute_input":"2022-01-16T23:20:10.730685Z","iopub.status.idle":"2022-01-16T23:20:10.736842Z","shell.execute_reply.started":"2022-01-16T23:20:10.730655Z","shell.execute_reply":"2022-01-16T23:20:10.736062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###### b. Write a program to find out the second smallest number in the list given below. (0.5 point) li=[32, 3, 5, 8, 33, 7] & Expected output: 5","metadata":{}},{"cell_type":"markdown","source":"1. Use sort() method to sort the list. It sorts in ascending order by default.\n2. Lists are mutable. sort() method changes it.\n3. Use Indexing operator with parameter 1 to get the smallest value.","metadata":{}},{"cell_type":"code","source":"li = [32, 3, 5, 8, 33, 7]\nli.sort() \nli[1] ","metadata":{"execution":{"iopub.status.busy":"2022-01-16T23:20:10.738375Z","iopub.execute_input":"2022-01-16T23:20:10.738991Z","iopub.status.idle":"2022-01-16T23:20:10.748803Z","shell.execute_reply.started":"2022-01-16T23:20:10.73895Z","shell.execute_reply":"2022-01-16T23:20:10.748047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###### c. Find out the unique values of the list given below. (0.5 point) mylist=[1,1,5,3,3,6,11,11] & Expected output: [1,5,3,6,11]","metadata":{}},{"cell_type":"markdown","source":"1. Import numpy. \n2. Convert the list into a numpy array.\n3. Use unique method on it and print out the array.","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\nmylist = [1,1,5,3,3,6,11,11]\n\nmylist = np.array(mylist)\n\nprint(np.unique(mylist))","metadata":{"execution":{"iopub.status.busy":"2022-01-16T23:20:10.749979Z","iopub.execute_input":"2022-01-16T23:20:10.750202Z","iopub.status.idle":"2022-01-16T23:20:10.763077Z","shell.execute_reply.started":"2022-01-16T23:20:10.750174Z","shell.execute_reply":"2022-01-16T23:20:10.762458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###### d. Write a program to print cube root of 216 using appropriate syntax. (0.5 point) Expected output: 6","metadata":{}},{"cell_type":"markdown","source":"1. Python deals reads every numeral as float while making calculations but truncates unnecessary digits to save memroy.\n2. 1/3 is a little bigger than its decimal counterpart 0.3333333...\n3. So, when we apply a power of 1/3 to 216, we will get 5.999999... \n4. Python interpreter takes 1/3 to be 0.3333333333333333 (16 decimal places)\n5. So, we might expect puttin the power as 0.33333333333333333333333333333333 (32 decimal places) might result in a more accurate result. But that is not so.\n6. Best is to round() the values to 5 decimal places for a better accuracy. Then we will get 6.0.","metadata":{}},{"cell_type":"code","source":"import math #to use pow() and round()\n\nround(pow(216,1/3),3)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T23:20:10.764006Z","iopub.execute_input":"2022-01-16T23:20:10.764625Z","iopub.status.idle":"2022-01-16T23:20:10.775261Z","shell.execute_reply.started":"2022-01-16T23:20:10.764584Z","shell.execute_reply":"2022-01-16T23:20:10.774562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### 2. Replace the value 'hello' in the below nested list with 'bye'. (1 point) a = [1, 2, [3, 4, 'hello']] & Expected output: [1, 2, [3, 4, 'bye']]","metadata":{}},{"cell_type":"markdown","source":"1. The last element in a is a list with 'hello' as its last element.\n2. So we access it with two subs (assignment operators), and assign 'bye' to it.","metadata":{}},{"cell_type":"code","source":"a = [1, 2, [3, 4, 'hello']] \n\na[-1][-1] =\"bye\"\n\nprint(a)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T23:20:10.777848Z","iopub.execute_input":"2022-01-16T23:20:10.778564Z","iopub.status.idle":"2022-01-16T23:20:10.787352Z","shell.execute_reply.started":"2022-01-16T23:20:10.778522Z","shell.execute_reply":"2022-01-16T23:20:10.786795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### 3. Given the below dictionary, write a program that returns [‘object0’]. (1 point) dict = {'a':9, 'b':(2,3,1), 'c':['object0','object1','object2']} Expected output: [‘object0’]","metadata":{}},{"cell_type":"markdown","source":"1. Access the third value (a list) of dict by putting 'c' in Indexing Operator.\n2. Access object0 (the first element in the list 'c') by appending a second Indexing operator.\n3. We are expected an output ['object0'], a list with one element. \n4. So convert it into a list by putting the single element in []","metadata":{}},{"cell_type":"code","source":"dict = {'a':9, 'b':(2,3,1), 'c':['object0','object1','object2']}\n\n[dict['c'][0]]","metadata":{"execution":{"iopub.status.busy":"2022-01-16T23:20:10.7883Z","iopub.execute_input":"2022-01-16T23:20:10.788971Z","iopub.status.idle":"2022-01-16T23:20:10.802355Z","shell.execute_reply.started":"2022-01-16T23:20:10.788938Z","shell.execute_reply":"2022-01-16T23:20:10.801526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### 4. Write a program to calculate the area of a circle. The program should ask for an appropriate input and print the computed area. (2 points)\n1. Input text: Please enter the radius of the circle.\n2. If the user enters a value of 5. The output should be: The area of the circle is 78.54\n3. This program should indicate that the input is invalid if the user enters a character instead of a number as input. For instance if the user enters a value of ‘a’ instead of 5 in the previous example the program should prompt: Invalid input, please enter a number: _","metadata":{}},{"cell_type":"markdown","source":"1. Import math module so pi and round() can be used\n2. Input radius from user. Let it remain a str.\n3. Run a while loop to input a float radius. It will run till the user inputs a valid float.\n4. Use try-except block to neglect non-float user inputs.\n5. Try-except block avoids traceback when we convert str to float.\n6. We will come out of the while loop with break statement when the user inputs a valid float.\n7. Use mathematical formula (pi r square) to get the area.\n8. Use round(,2) to round to two decimal places, because that's what is expected.","metadata":{}},{"cell_type":"code","source":"import math\n\nradius = input(\"Please enter the radius of the circle.\\n\")\n\nwhile radius != float: \n    try:\n        radius = float(radius) #if this is false, Python will switch to except block\n        break #if the above is true, we have our radius. And we come out of the try-except block\n    except:\n        print(\"Invalid input, please enter a number: _\")\n        radius = input()\n\narea = round(math.pi*radius*radius,2)\nprint(f\"The area of the circle is {area}\")","metadata":{"execution":{"iopub.status.busy":"2022-01-16T23:20:10.803409Z","iopub.execute_input":"2022-01-16T23:20:10.803754Z","iopub.status.idle":"2022-01-16T23:20:16.667914Z","shell.execute_reply.started":"2022-01-16T23:20:10.803721Z","shell.execute_reply":"2022-01-16T23:20:16.667079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### 5. Write a program which will take two lists X & Y as input and it will return a list having all the odd numbers present in the two lists. (Note:- common elements can be repeated) (2 points)\n##### Input list: X=[1,2,3,4,5] & Y=[5,6,7,8,9] Expected Output: [1,3,5,5,7,9] or [1,3,5,7,9] both are accepted.","metadata":{}},{"cell_type":"markdown","source":"1. Define a function get_int_list so it can be reused to get two lists.\n    - Use a combination of try-except block in while loop to get in the elements of the list\n2. Input two lists X and Y using the get_int_list()\n3. Add Y to X using append method. It will mutate X, with which we will work further.\n4. Iterate through X using range function in list comprehension with required condition. Feed it the element fulfilling the condition in a new list Z with odd numbers.","metadata":{}},{"cell_type":"code","source":"def get_int_list(): #Step 1\n    X = list()\n    x = None\n    print(\"Enter integer elements for the list. Press a non-integer when you are done.\")\n    while x != 'done':\n        x = input()\n        try:\n            x = int(x)\n            X.append(x)\n        except:\n            x = 'done'\n    return X\n\nX = get_int_list() #Step 2\nY = get_int_list()\n\nX.extend(Y) #Step 3 \n\nZ = [p for p in range(len(X)) if p%2 != 0] #Step 4\n    \nprint(f\"\\nThe list having all the odd numbers present in the two input lists is:\\n{Z}\")  ","metadata":{"execution":{"iopub.status.busy":"2022-01-16T23:20:16.669308Z","iopub.execute_input":"2022-01-16T23:20:16.670174Z","iopub.status.idle":"2022-01-16T23:21:01.75761Z","shell.execute_reply.started":"2022-01-16T23:20:16.670125Z","shell.execute_reply":"2022-01-16T23:21:01.756761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###### 6. Write a function that prints the integers from 1 to 15. But for multiples of three print \"GREAT\" instead of the number, and for the multiples of five print \"LEARNING\". For numbers which are multiples of both three and five print \"GREATLEARNING\". (2 points)","metadata":{}},{"cell_type":"markdown","source":"1. Define a function design_string\n- 1.1 Define a list list1 with integers between 1 to 15 using range() function.\n- 1.2 Using for loop, iterate through a similar range and manipulate the elements of the list.\n- 1.3 Do not iterate through the list directly, because one of the numbers 15 is a multiple of other numbers 5 and 3.\n- 1.4 Use * unpacking operator to print the elements of the altered list.\n2. Run the function","metadata":{}},{"cell_type":"code","source":"def design_string():\n    list1 = list(range(1,16)) #1.1 & 1.3\n    for n in range(1,16): #1.2\n        if n%3 == 0:\n            list1[n-1] = \"GREAT\" \n        if n%5 == 0:         \n            list1[n-1] = \"LEARNING\"\n        if n%15 == 0:\n            list1[n-1] = \"GREATLEARNING\"\n    print(*list1, sep = ', ') #1.4\n\ndesign_string() #2","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-01-16T23:21:01.758768Z","iopub.execute_input":"2022-01-16T23:21:01.759186Z","iopub.status.idle":"2022-01-16T23:21:01.767987Z","shell.execute_reply.started":"2022-01-16T23:21:01.759143Z","shell.execute_reply":"2022-01-16T23:21:01.76717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Part-II (10 Points)\n### Dataset: Online_sales.csv\n#### Domain: Retail\n##### Objective: Analyzing sales data to understand sales trend","metadata":{}},{"cell_type":"markdown","source":"##### 1. Import necessary libraries and read the provided dataset (online_sales.csv) and check the top 5 and random 5 samples of the dataframe. (0.5 point)","metadata":{}},{"cell_type":"markdown","source":"1. The \"online_sales.csv\" file is in the same folder the one in which Python_ProjectNo1 notebook file is.\n2. head() method of Pandas DataFrame gives first five rows\n3. sample() gives any 5 randome rows.","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2022-01-16T23:21:01.769167Z","iopub.execute_input":"2022-01-16T23:21:01.769525Z","iopub.status.idle":"2022-01-16T23:21:01.784681Z","shell.execute_reply.started":"2022-01-16T23:21:01.769495Z","shell.execute_reply":"2022-01-16T23:21:01.784045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndataset = pd.read_csv(\"../input/iiitd-project1/online_sales.csv\")\n\ndataset.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-16T23:21:01.78595Z","iopub.execute_input":"2022-01-16T23:21:01.786384Z","iopub.status.idle":"2022-01-16T23:21:02.141636Z","shell.execute_reply.started":"2022-01-16T23:21:01.786349Z","shell.execute_reply":"2022-01-16T23:21:02.140847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.sample(5)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T23:21:02.142776Z","iopub.execute_input":"2022-01-16T23:21:02.143034Z","iopub.status.idle":"2022-01-16T23:21:02.164132Z","shell.execute_reply.started":"2022-01-16T23:21:02.143004Z","shell.execute_reply":"2022-01-16T23:21:02.163297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 2. Check info of the dataframe and write your observations. Comment on data types and shape of the dataset. (0.5 point)","metadata":{}},{"cell_type":"code","source":"#info method gives a summary statistics of the dataframe\ndataset.info()\ndataset.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-16T23:21:02.165708Z","iopub.execute_input":"2022-01-16T23:21:02.166258Z","iopub.status.idle":"2022-01-16T23:21:02.321967Z","shell.execute_reply.started":"2022-01-16T23:21:02.166214Z","shell.execute_reply":"2022-01-16T23:21:02.321136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###### Comments\n1. It is a dataset of online sales of a firm. \n2. There are 8 columns, and hence 8 variables through which the data is viewed.\n3. There are 240007 rows. The shape is (240007, 8). It is a fairly large dataset.\n4. InvoiceNo is an object (str or mixed), which could have come as a surprise, because we would expect it to be numeric. But one, we don't want any kind of accidental change in the InvoiceNo. And two, even though all the sample values seem numeric in the current dataset, we can have alphanumeric/numeric characters in an InvoiceNo.\n5. CustomerID is a float64 which seems weird. It could easily have been int64 like Quantity. It occupies more memory space than required.\n6. InvoiceDate is an object, which was expected. We often deal with str inputs in columns of datetimes. We would have to convert it into datetime when time comes.  \n7. There are many null values in the dataset, specially the CustomerIDs. We may have to drop them. Dropping them won't affect our analysis much, because we have a lot of rows.","metadata":{}},{"cell_type":"markdown","source":"#### 3. Check for null values and report the percentage of null values of each column.And drop the rows having null values in it. (1 point)","metadata":{}},{"cell_type":"markdown","source":"\n- STEPS:\n1. Use isna() method to check for null values. It returns a mask of bool values for each element in dataset that indicates whether an element is an NA value or not. Each NaN is booled as True i.e. 1.\n2. Apply sum() method to the above mask to return a Series of sums of 1's for each column.\n3. Convert the Series of [columns, sums of NaNs] into a DataFrame using pd.DataFrame() for better visualisation and manipulation. Call this new dataframe as d_null.\n4. Use columns attribute to name the one column d_null has as NoOfNull.\n5. Use apply method to add a new column(axis = 1) called PercentNull. \n6. In apply(), use lambda function to perform the required operation on each instance of NoOfNull \n7. Print d_null. That would report the percentage of null values of each column of the dataset","metadata":{}},{"cell_type":"code","source":"d_null = dataset.isna().sum() #Steps 1,2\n\nd_null = pd.DataFrame(d_null) #Step 3\n\nd_null.columns = ['NoOfNull'] #Step 4\n\nd_null['PercentNull'] = d_null.apply(lambda row: (row.NoOfNull/len(dataset))*100 , axis = 1) #step 5,6\n\nprint(d_null) #Step 7","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-01-16T23:21:02.325509Z","iopub.execute_input":"2022-01-16T23:21:02.325739Z","iopub.status.idle":"2022-01-16T23:21:02.468437Z","shell.execute_reply.started":"2022-01-16T23:21:02.32571Z","shell.execute_reply":"2022-01-16T23:21:02.467452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###### To drop the rows having null values in it\nSTEPS:\n1. use dropna() method to drop all NaN values.\n2. use info() method to display the change\n- NOTE: I am making a new DataFrame for this question. In Practice, I would have altered the original dataset with reassignment. But I want the examiners to be able to come back and check, and any alteration in dataset is permanent. ","metadata":{}},{"cell_type":"code","source":"dataset_NoNull = dataset.dropna() #Step 1\ndataset_NoNull.info() #Step 2","metadata":{"execution":{"iopub.status.busy":"2022-01-16T23:21:02.469682Z","iopub.execute_input":"2022-01-16T23:21:02.469999Z","iopub.status.idle":"2022-01-16T23:21:02.723756Z","shell.execute_reply.started":"2022-01-16T23:21:02.469956Z","shell.execute_reply":"2022-01-16T23:21:02.722889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### 5. Drop the instances having quantity less than zero. (1 point) (Note:- refer to the ‘Quantity’ feature)","metadata":{}},{"cell_type":"markdown","source":"###### NOTE: I am solving Q 5 before Q 4, because we don't want negative Quantity values in a dataset when performing a statistical analysis on it.\n\n- STEPS\n1. Get the indices with negative Quantity instances with by\n    - selecting the rows where Quantity<0, and\n    - selecting the indices of those rows with index attribute\n    - Store the indices in i\n2. Use drop() method to remove the selected indices contained in i. Have inplace parameter as False so the original dataset does not change.\n3. clean_data is the resultant dataset which has no null values and no rows with negative Quantity values. We will use this dataset from now on.","metadata":{}},{"cell_type":"code","source":"i = dataset_NoNull[dataset_NoNull['Quantity'] < 0].index #Step 1\n\nclean_data = dataset_NoNull.drop(i, axis = 'rows', inplace = False) #Step 2\n\nclean_data.info() #3 ","metadata":{"execution":{"iopub.status.busy":"2022-01-16T23:21:02.72481Z","iopub.execute_input":"2022-01-16T23:21:02.725035Z","iopub.status.idle":"2022-01-16T23:21:02.856835Z","shell.execute_reply.started":"2022-01-16T23:21:02.725007Z","shell.execute_reply":"2022-01-16T23:21:02.855851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 4. Check the statistical summary of the dataset. (Use inbuilt functions) (0.5 point)","metadata":{}},{"cell_type":"markdown","source":"1. I will work on clean_data, which is what we should ideally work with. That is why I decided to solve Q 5 first.\n2. REASON (IMPORTANT): \n- About 28% of CustomerId values are NaN. We have to take them as bogus as every Invoice should have a CustomerId. How can a record have an InvoiceNo but no CustomerId? \n- Also, Quantity vaues cannot be negative. So, bogus data. Description does not matter, as it seems  optional. But a very small percentage of data loss would be there (0.37% bogus data). And with so many entries at hand, we can handle that data loss. ","metadata":{}},{"cell_type":"code","source":"dataset_NoNull.describe() \n#Here min value of Quantity is -74215, which is inadmissible","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-01-16T23:21:02.858046Z","iopub.execute_input":"2022-01-16T23:21:02.858259Z","iopub.status.idle":"2022-01-16T23:21:02.894745Z","shell.execute_reply.started":"2022-01-16T23:21:02.858233Z","shell.execute_reply":"2022-01-16T23:21:02.89417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Solution to Q 4\n\n- STEPS\n1. Use descibe() method to give basic descriptive statistical summary. It chooses only those columns which have numeric values as instances.\n2. Note: describe() on clean_data gives us more valid values. Case in point: min(Quantity) is now 1","metadata":{}},{"cell_type":"code","source":"clean_data.describe() #Step 1","metadata":{"execution":{"iopub.status.busy":"2022-01-16T23:21:02.895582Z","iopub.execute_input":"2022-01-16T23:21:02.896083Z","iopub.status.idle":"2022-01-16T23:21:02.928402Z","shell.execute_reply.started":"2022-01-16T23:21:02.89605Z","shell.execute_reply":"2022-01-16T23:21:02.927826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### 6. Check unique values of the country and report the name of the country that has the highest number of instances/rows. (0.5 point)","metadata":{}},{"cell_type":"markdown","source":"###### Unique values of the country\n- STEPS:\n1. Extract the Country column using dot operator from the clean_data as a Series\n2. Apply unique() method to it to have only unique values in an array unique_values\n3. Print to give out Unique values of the country. Use * unpacking operator to get comma separated values.","metadata":{}},{"cell_type":"code","source":"unique_values = clean_data.Country.unique() #Step 1,2\n\nprint(\"Unique values of the country in the dataset are:\\n\")\nprint(*unique_values, sep = ', ') #Step 3","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-01-16T23:21:02.92923Z","iopub.execute_input":"2022-01-16T23:21:02.929832Z","iopub.status.idle":"2022-01-16T23:21:02.954301Z","shell.execute_reply.started":"2022-01-16T23:21:02.929801Z","shell.execute_reply":"2022-01-16T23:21:02.953471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###### Report the name of the country with highest number of instances.\n- STEPS\n1. Group the dataset according to Country column using groupby method \n2. Aggregate by count() method choosing any column (all will give the same). I choose Description. It will give us a Pandas Series.\n3. Convert the resultant Series into a dictionary dict1 using to_dict() Series method\n4. Use lambda in max() function to iterate through each value of dict, and get the key (country) with maximum value. Print the result.","metadata":{}},{"cell_type":"code","source":"dict1 = clean_data.groupby('Country').count().Description.to_dict() #Steps 1,2,3\n\nprint(f\"The country with highest number of instances is: {max(dict1, key = lambda x: dict1[x])}\") #Step 4","metadata":{"execution":{"iopub.status.busy":"2022-01-16T23:21:02.955392Z","iopub.execute_input":"2022-01-16T23:21:02.955616Z","iopub.status.idle":"2022-01-16T23:21:03.073489Z","shell.execute_reply.started":"2022-01-16T23:21:02.955586Z","shell.execute_reply":"2022-01-16T23:21:03.07255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### 7. Create a new column with the name as ‘sales’ having total sales. The total sales is defined as Quantity*UnitPrice. (1 point)b","metadata":{}},{"cell_type":"markdown","source":"STEPS:\n1. Add a column with Index operator.\n2. Assign it values using list comprehension\n3. In list comprehension, zip two variables x and y, corresponding to values in columns Quantity and Price and get the result x*y assigned to new column","metadata":{}},{"cell_type":"code","source":"clean_data['sales'] = [x*y for (x,y) in zip(clean_data['Quantity'],clean_data['UnitPrice'])] #Steps 1,2,3\n\nclean_data.head()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-01-16T23:21:03.075045Z","iopub.execute_input":"2022-01-16T23:21:03.07602Z","iopub.status.idle":"2022-01-16T23:21:03.197603Z","shell.execute_reply.started":"2022-01-16T23:21:03.075962Z","shell.execute_reply":"2022-01-16T23:21:03.196809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### 8. Report the top 5 countries in terms of sales. (2 points)","metadata":{}},{"cell_type":"markdown","source":"###### a. Considering the size of the sales\n- STEPS:\n1. Group clean_data by Country using groupby method. Groups attribute is like dictionary whose keys are the computed unique groups and corresponding values being the axis labels belonging to each group. \n2. Aggregate the resulting group with sum()\n3. Extract 'sales' column by using dot operator over the aggregate.Now we will have a Series.\n4. Sort the Series by value using sort_values() object. Make ascending attribute as False to sort in descending form.\n5. Apply index operator to the sorted Series to extract first five index elements, which are country names.","metadata":{}},{"cell_type":"code","source":"by_sales_size = clean_data.groupby('Country').sum().sales.sort_values(ascending = False).index[0:5] #Steps 1,2,3,4, 5\n\nprint(\"Top five countries in terms of sales size are:\")\nprint(*by_sales_size, sep= ', ')","metadata":{"execution":{"iopub.status.busy":"2022-01-16T23:21:03.199194Z","iopub.execute_input":"2022-01-16T23:21:03.19949Z","iopub.status.idle":"2022-01-16T23:21:03.247285Z","shell.execute_reply.started":"2022-01-16T23:21:03.19945Z","shell.execute_reply":"2022-01-16T23:21:03.246445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###### b. Consider the mean value of sales.\n- STEPS:\n1. Repeat all the steps as in 8(a) except for one change. Aggregate with mean() function instead of sum().","metadata":{}},{"cell_type":"code","source":"by_sales_mean = clean_data.groupby('Country').mean().sales.sort_values(ascending = False).index[0:5] \n\nprint(\"Top five countries in terms of mean sales are:\")\nprint(*by_sales_mean, sep= ', ')","metadata":{"execution":{"iopub.status.busy":"2022-01-16T23:21:03.248756Z","iopub.execute_input":"2022-01-16T23:21:03.249071Z","iopub.status.idle":"2022-01-16T23:21:03.293144Z","shell.execute_reply.started":"2022-01-16T23:21:03.24903Z","shell.execute_reply":"2022-01-16T23:21:03.292238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### 9. Report the top 5 products which bring the highest sales. Use StockCode for product information. (1 point)","metadata":{}},{"cell_type":"markdown","source":"- STEPS:\n1. Use is_unique attribute on the Series clean_data.StockCode to check if the column has unique values. It turns out to be False. So we have to group clean_data by StockCode first. \n2. Group clean_data by 'StockCode' using groupby method. And aggregate the resulting group with sum().\n3. Extract 'sales' column by using dot operator over the aggregate. Now we will have a Series.\n4. Sort the Series by value using sort_values() object. Make ascending attribute as False to sort in descending order.\n5. Apply index operator to the sorted Series to extract first five index elements, which are Stock codes for top 4 products bringing in highest sales. ","metadata":{}},{"cell_type":"code","source":"top_5_products = clean_data.groupby('StockCode').sum().sales.sort_values(ascending = False).index[0:5] #Step 2,3,4,5\n\nprint(\"Top five products bringing the highest sales have the StockCodes as:\")\nprint(*top_5_products, sep= ', ')","metadata":{"execution":{"iopub.status.busy":"2022-01-16T23:21:03.294565Z","iopub.execute_input":"2022-01-16T23:21:03.295198Z","iopub.status.idle":"2022-01-16T23:21:03.345005Z","shell.execute_reply.started":"2022-01-16T23:21:03.295147Z","shell.execute_reply":"2022-01-16T23:21:03.344287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### NOTE:\nI tried fetching 'Description' values of corresponding 'StockCode' values. They are 'WHITE HANGING HEART T-LIGHT HOLDER', 'PICNIC BASKET WICKER SMALL','REGENCY CAKESTAND 3 TIER', 'PARTY BUNTING' 'MEDIUM CERAMIC TOP STORAGE JAR', 'PICNIC BASKET WICKER 60 PIECES'.\n\nI used the following code:\nimport numpy as np\ntop_5_p = clean_data.iloc[np.where(clean_data.StockCode.isin(top_5_products))].Description.unique()\ntop_5_p\n\nClearly on of the StockCode values relates to two Description values, most probably 'PICNIC BASKET WICKER SMALL' and 'PICNIC BASKET WICKER 60 PIECES'. So, I left the result to mentioning StockCodes.","metadata":{}},{"cell_type":"markdown","source":"##### 10. Convert the ‘InvoiceDate’ into a date format and report the month on which the maximum sales occur? (2 points)","metadata":{}},{"cell_type":"markdown","source":"###### Convert the ‘InvoiceDate’ into a date format\n- STEPS:\n1. Use to_datetime() method over the 'InvoiceDate' column of clean_dataset ","metadata":{}},{"cell_type":"code","source":"clean_data['InvoiceDate'] = pd.to_datetime(clean_data['InvoiceDate'])\nprint(f\"The object type of column 'InvoiceDate' now convert into date format i.e. {clean_data['InvoiceDate'].dtypes}\")","metadata":{"execution":{"iopub.status.busy":"2022-01-16T23:21:03.346535Z","iopub.execute_input":"2022-01-16T23:21:03.346767Z","iopub.status.idle":"2022-01-16T23:21:04.16945Z","shell.execute_reply.started":"2022-01-16T23:21:03.346733Z","shell.execute_reply":"2022-01-16T23:21:04.168531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### report the month on which the maximum sales occur\nSTEPS:\n1. Create a new column 'month' from 'InvoiceDate' using DatetimeIndex.strftime() method.\n    - DatetimeIndex.strftime() gives out an Index of string values of a format supplied to it.\n    - Put in %B as parameter to force out full month name. \n2. Group the dataset by 'month' and Aggregate with sum() and save the dataframe in month_max.\n3. Extract 'sales' from month_max using dot operator. Now it becomes a Pandas Series.\n4. Sort the values in the Series of (months,sales). In descending order because we need the month with maximum sales.\n5. Use Index operator on the ordered Series to get the first value- which is what we were after.","metadata":{}},{"cell_type":"code","source":"clean_data['month'] = pd.DatetimeIndex(clean_data['InvoiceDate']).strftime(\"%B\") #Step 1\n\nmonth_max = clean_data.groupby('month').sum().sales.sort_values(ascending = False).index[0] #Steps 2,3,4,5\n\nprint(f\"The month on which maximum sales occur is {month_max}\")","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-01-16T23:21:04.170626Z","iopub.execute_input":"2022-01-16T23:21:04.170877Z","iopub.status.idle":"2022-01-16T23:21:05.475466Z","shell.execute_reply.started":"2022-01-16T23:21:04.170846Z","shell.execute_reply":"2022-01-16T23:21:05.474494Z"},"trusted":true},"execution_count":null,"outputs":[]}]}